{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveen-1-1/hybrid-finetuning-ecommerce-llm-agent-bot/blob/main/NLP_LLM_Testing_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft accelerate bitsandbytes\n",
        "!pip install -q sentence-transformers faiss-cpu\n",
        "!pip install -q rouge-score bert-score\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P93agMWGFGNW",
        "outputId": "b00cf04a-c203-4afd-b413-d8f33592acf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq1ytKNNFYR8",
        "outputId": "6bf44811-8bec-4af7-e98f-d63b2ead7752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36341c1196124fd6ba212ee6eff9b670",
            "d088c49d494544c099769d6ed9e142e6",
            "d49c8075ef154a75ba56b0f3452d807f",
            "a0f5416daa4c40d69e653d6bd516f8c8",
            "2eece33c34114284bf6d3d02c6dfc8cb",
            "2b65e689502748718eccbaa2977e948f",
            "2c8335343c4f4f7493ade0e4eabb4af5",
            "4e9e05ee847947bb850fe99e86ba69f0",
            "87c4017cc1e243ddaafa72bea8645cbf",
            "0ef2b0ef428d413a9d12ee18f3af3d1a",
            "80460ae16ebc4659ba84b3608054a6ee",
            "308b81447c6948dc8469082fd4dd3526",
            "169490174bbb4705b909353c25e8fe1b",
            "b3db39ad62014037994b095ff5e9777d",
            "93bd20007aae4cdb85ebb735228c4b34",
            "bdab05ccaa21431cab07cbf377a18084",
            "7414d0a5ff864b6a9a40f0b7a00e4f7e",
            "2faa0bc4efe04cceadbfb229583ee764",
            "c83c928ac37f44e6a2032de46d292d88",
            "e197de7f2b8d4f4994f8f0a050fb08e5",
            "51ebf27177f148eeb22bf93c639cc878",
            "9fa6bae5e0db4a8388402bdb4456d90a",
            "6954348ea27d4b078b7b7ecaab07c57e",
            "e2e1cd35a3a248018dc598d580ce7d55",
            "3bce5eb1a5ce40208febe2aeffb2b066",
            "828474d6c02942f3b2c783604acffacc",
            "21ed1fe71b9445cca818bc22a6abe98c",
            "a239a5a9d1b543ae9f879d3ef753519d",
            "6bf477c3b6df45f0897e7f7e18a1c8b0",
            "8bed6d0999974c51a19d78afcf7e6d1e",
            "2a9c5d09e8c94eb99b08366c31bc449b",
            "7051c464fc134917b47313b8a31c28ea",
            "48b7d108ca274cd0a174c88383e34e60",
            "09fdb6731a384eba86efca52ed08597d",
            "7a1fe623cf6b4bd08cd42ce04c98580c",
            "28cd8868283a4412afaa1d9c1b7b7dca",
            "942ada46d7754e74afbc825be5a6c4fb",
            "0934200bf73f423e853ee262e02471dd",
            "c94576bfcf5848b2bbec4fbe6ca23813",
            "0157d20f604b4324b78c54c60446060e",
            "e6748220df6d4b95be6becccf4346591",
            "7ce5164989e24180a32d5f4cbd65a668",
            "d59759de30254f579dbcae339b65a3b9",
            "ff4697d906194ef1b11c67976a65b185",
            "bac607a29b864f96b9386b36da1b2fc3",
            "3572abe248ac40d78593131ba70b66c9",
            "ddccdfa466734ccaa60ee6cf67a3da69",
            "9471a58751ee410babefa2f7befdb428",
            "c3219d7d40de429ca354aace64680d00",
            "f9109c6fd47945c8b62fd704bc883c14",
            "98a4bb1b79bb4b6193d35beb5e888e6d",
            "fbefac5b81e94eada1351a003816e3b8",
            "d660b70c5b5b49e19e5fde8d04b94ac3",
            "d60b249ed4ba4197a86d06b68f90138a",
            "4e7c3f0594954189944f01fecd7318c2",
            "d9f921da7946489586eea948397bfe0b",
            "ee1eab99eef047b68f0a0dfb8d48d5e1",
            "44974ac8ad5d4bfc86563d11864edd9e",
            "42653b91a72040df915729c3c6a8de31",
            "a1d8709aee0c49d39d74d7511e765e22",
            "5c5ccf4b5e2a42be808fc1d52a1a1d44",
            "ac317ccb6dc0473087ffdf002bd96e8a",
            "2c152a2b16af4735894d246d4e101e48",
            "74c96fcb1a874b7fb04115950fca3549",
            "43c44bd6145e469ebcf62338ac6b8a79",
            "c59c7501d1af4b4ea47c508cb4ce87db",
            "148766cf4bb14c6b9731613d45e2030d",
            "8f3fe9e8289a4b0894a37d45d90a0cf0",
            "a22ceb41c4c948c88412a89a69a4efe2",
            "69990781804d4316a813ac7d5d0fd474",
            "ad41e966dbda4204ae3cc1cfc32a1fbb",
            "b4f42c1116ad401fbe860c7328b4a23f",
            "42202229799c4f76aed4955e88bbd31f",
            "1cbdac6ad8d94cfaac13cb7f1311cf1c",
            "2fe316681d2c45f68084fb6417aac31d",
            "27c99f720c57434fa26423221863fc30",
            "c61d5554e6944e59b137de14d8835695",
            "fe67ad30719a4d68b36fec8244fccd50",
            "c2083182458c455083cbf8e11e27295f",
            "0258a6763f62455a81a02b1f8a13648e",
            "4de0fcb196894f4b84302fe1c5e8f4fd",
            "6800527b39cc4dbd9b2104d7d12906b4",
            "9ca126e0a6374c538924cd8b0f320048",
            "cf4c2db368634c958946a28123ac0cd0",
            "c7fbf572ac6a4da49bb16867c419f97d",
            "e1c210f7cb5d4f8ca06ba58ef85a1dac",
            "3148040939bb4d81964305bb7bde3b5a",
            "6d1a6818ecb649dab809a39ccaf9bad6",
            "c540208d6fc4413d9c8848d672704b43",
            "661b73d9551747e79785d713572b07a0",
            "d5ddabab79d94138aa3cc2fd7f2ce919",
            "a89a02070260400db9b3010885c3242b",
            "83e956a6655d401b8935a594560de092",
            "e317a5666d794565852742ed1ee47aa3",
            "ad0869424d5f4dc69698548115485eb0",
            "eceb2096adb74258ac9fc118dc4190ab",
            "0ce6849aced64151829ad360ee74faa4",
            "cb8d92ac563c47c69a8661987a69bd32",
            "7427d04dc5114786aed926cb8e679cb2",
            "eadd6d30c1df47cebc9d86f3e07e038d",
            "9e6855b7f5a247319eb979cb58d35e67",
            "51a2d1ca031948baa7652f378ffb7087",
            "268ccd89b8574e21916d4a12a6e936cf",
            "bfbc73a282664000b5b05ba23a6b2072",
            "b50aebf666bf43d89203a3cc3e9680b7",
            "b412651d640a4ef2898f2741cd802f9b",
            "f2dc5f1f717e412496792efc1920e1cd",
            "a04a3c5ddda644e4b9f768a4fe139f07",
            "a6ca3388151140aeb274b59f4acdb24a",
            "23d01e8c2098446fb321333b01ea840d",
            "f27beed907c343b8948935b38b76e928",
            "8bcbe11f4dc344daa589d0ea47af879f",
            "62c55b4882f4431397f01a207f866058",
            "d956cba394804fe19b67fb6bd8827bd0",
            "f660831ff9bc4435962c8af28eecaf73",
            "44148961093e46c5a383b51c7be66676",
            "2adea477d1c14568b222c54a585f76e6",
            "121f13f0d25945909e4082d5675029bb",
            "c1af55bfa4b2468f91ccb8281c84cef9",
            "7bfd9bc6e7414ca6a231305d7cedef69",
            "d6a6f3b4932d4259866f83200b4c37a4",
            "76a2e97fa4a6434fad902620ac08306c",
            "11a87e8e4c674f15b16598d306ed83bc",
            "e74e9adffc9547a09b556975b3fac042",
            "20ccbaceb15a43f39af2c15776762fc4",
            "30cc15533acc45cc88f51609938923a2",
            "5c2452f837144c2bbf2a2b2d9293551c",
            "8973cff04dc84b2dbfe0bf213caef3b9",
            "d57d8143b4f24a459177563e2e5bbded",
            "3613a09951bd4d1c805e40585adb7af4",
            "3181aa67ae7e47d888fe01e3e19b379d",
            "178213b8dbd744ebb0e7d5ad10d99618",
            "a2744a9d948b4438a3fd51b0dd2f23b8",
            "9d2c592cdbb040cc9c97f6a42c06110d",
            "8844a93867234f3f9a1f5153016c5a2b",
            "aebf965bf9144885b3adacc507106b8f",
            "f4e050f21a4e4e1b82ea95a1e8b8d550",
            "a62cc850683b49b38a78de57b8ad8c6d",
            "83726d5cf97c43dabca709a9058a4068",
            "27de16ea45834946adc60beca69a2f7f",
            "624516e695ed46a7b4cac215e9fa8c93",
            "2f3ea0b1dd1049a983011c4ed9832955",
            "eb265e4bbbeb4d14965e9e51957399ef",
            "3fc8c5dd523f496ea73f4b7a66dbb840",
            "bede98bb2fda48039a50b4a41610ceae",
            "d917125da70547ceaf51a52f49c483ff",
            "e64d7a3bbd984f24b22ce58275d4dd2e",
            "f9cd11e63a0b4ba28a6ffd7128c52916",
            "c51de9391a664dfe8529b54c4c6a1feb",
            "71d711fcc0e64ceea71cfbdfaa63b433",
            "dbbfb3870c5b4cfda040a158bb357761",
            "0946659aabae42c283d561f10c90c996",
            "e82d1551f2e94011a44328fe0d0a0a78",
            "4ce8c7f547de433ebc2c6795856e56ea",
            "462dcf1516aa4ac2b80650f6d0132399",
            "d868da935002425cbb37eca4e6955d6a",
            "38c096c30e164ef58cd0cefb356d5989",
            "914af8173547431e98f9a91584f38e12",
            "86143b90f114474c9dda35fc037dcc24",
            "255c3770a67d40e6956fbafc1d1b5878",
            "f73681be42624b5c8ead3121e8b7fd3c",
            "f701d33b3b6d44c5908eb9d971379752",
            "af0e2060354e46cb8deed3232d6a533e",
            "56cb87490a364094823e14aebc420011",
            "098527e5f8014cee8094419a4dbe8d17"
          ]
        },
        "id": "mhh14RBgE31I",
        "outputId": "9be062e7-dd73-4406-9706-d77b21b3ba39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "RETRIEVAL-ONLY BASELINE (ALL QUERY TYPES)\n",
            "======================================================================\n",
            "\n",
            "Training index: 13,921 Q&A pairs (ALL types)\n",
            "  - Deterministic: 5,542\n",
            "  - Indeterministic: 8,379\n",
            "\n",
            "Test set: 2,984 queries (ALL types)\n",
            "  - Deterministic: 1,188\n",
            "  - Indeterministic: 1,796\n",
            "\n",
            "1. Loading embedding model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36341c1196124fd6ba212ee6eff9b670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "308b81447c6948dc8469082fd4dd3526"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6954348ea27d4b078b7b7ecaab07c57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09fdb6731a384eba86efca52ed08597d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bac607a29b864f96b9386b36da1b2fc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9f921da7946489586eea948397bfe0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "148766cf4bb14c6b9731613d45e2030d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe67ad30719a4d68b36fec8244fccd50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c540208d6fc4413d9c8848d672704b43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eadd6d30c1df47cebc9d86f3e07e038d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f27beed907c343b8948935b38b76e928"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úì Model loaded\n",
            "\n",
            "2. Encoding all training queries...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/436 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76a2e97fa4a6434fad902620ac08306c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úì Encoded 13,921 queries\n",
            "\n",
            "3. Building FAISS index with ALL query types...\n",
            "   ‚úì Index built with 13,921 vectors\n",
            "\n",
            "4. Testing retrieval on ALL test queries...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/94 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2744a9d948b4438a3fd51b0dd2f23b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RETRIEVAL-ONLY RESULTS (ALL QUERIES)\n",
            "======================================================================\n",
            "\n",
            "K     Intent Match    Category Match \n",
            "----------------------------------------------------------------------\n",
            "1      99.03%         99.93%\n",
            "3      99.80%        100.00%\n",
            "5      99.90%        100.00%\n",
            "\n",
            "======================================================================\n",
            "BREAKDOWN BY QUERY TYPE\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/38 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fc8c5dd523f496ea73f4b7a66dbb840"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Deterministic queries (1188 queries):\n",
            "  Top-1 Intent Match: 98.57%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "462dcf1516aa4ac2b80650f6d0132399"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Indeterministic queries (1796 queries):\n",
            "  Top-1 Intent Match: 99.33%\n",
            "\n",
            "======================================================================\n",
            "KEY INSIGHT:\n",
            "======================================================================\n",
            "This shows how well PURE RETRIEVAL works when forced to handle\n",
            "BOTH deterministic (good fit) AND indeterministic (poor fit) queries.\n",
            "\n",
            "Expected: Deterministic does well, Indeterministic does poorly.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"RETRIEVAL-ONLY BASELINE (ALL QUERY TYPES)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load full dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "\n",
        "# Split into train/test (same split as before)\n",
        "_, df_temp = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
        "_, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, stratify=df_temp['label'])\n",
        "df_train, _ = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
        "\n",
        "print(f\"\\nTraining index: {len(df_train):,} Q&A pairs (ALL types)\")\n",
        "print(f\"  - Deterministic: {(df_train['label']==0).sum():,}\")\n",
        "print(f\"  - Indeterministic: {(df_train['label']==1).sum():,}\")\n",
        "\n",
        "print(f\"\\nTest set: {len(df_test):,} queries (ALL types)\")\n",
        "print(f\"  - Deterministic: {(df_test['label']==0).sum():,}\")\n",
        "print(f\"  - Indeterministic: {(df_test['label']==1).sum():,}\")\n",
        "\n",
        "# Load embedding model\n",
        "print(\"\\n1. Loading embedding model...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"   ‚úì Model loaded\")\n",
        "\n",
        "# Encode ALL training queries (not just deterministic)\n",
        "print(\"\\n2. Encoding all training queries...\")\n",
        "train_embeddings = embedding_model.encode(\n",
        "    df_train['instruction'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "print(f\"   ‚úì Encoded {len(df_train):,} queries\")\n",
        "\n",
        "# Build FAISS index\n",
        "print(\"\\n3. Building FAISS index with ALL query types...\")\n",
        "dimension = train_embeddings.shape[1]\n",
        "full_index = faiss.IndexFlatL2(dimension)\n",
        "full_index.add(train_embeddings.astype('float32'))\n",
        "print(f\"   ‚úì Index built with {full_index.ntotal:,} vectors\")\n",
        "\n",
        "# Test on ALL test queries\n",
        "print(\"\\n4. Testing retrieval on ALL test queries...\")\n",
        "test_embeddings = embedding_model.encode(\n",
        "    df_test['instruction'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "# Retrieve top-k\n",
        "k_values = [1, 3, 5]\n",
        "results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    distances, indices = full_index.search(test_embeddings.astype('float32'), k)\n",
        "\n",
        "    intent_matches = 0\n",
        "    category_matches = 0\n",
        "\n",
        "    for i, test_row in df_test.iterrows():\n",
        "        test_intent = test_row['intent']\n",
        "        test_category = test_row['category']\n",
        "\n",
        "        retrieved_indices = indices[df_test.index.get_loc(i)][:k]\n",
        "        retrieved_intents = df_train.iloc[retrieved_indices]['intent'].values\n",
        "        retrieved_categories = df_train.iloc[retrieved_indices]['category'].values\n",
        "\n",
        "        if test_intent in retrieved_intents:\n",
        "            intent_matches += 1\n",
        "        if test_category in retrieved_categories:\n",
        "            category_matches += 1\n",
        "\n",
        "    results[k] = {\n",
        "        'intent_accuracy': intent_matches / len(df_test) * 100,\n",
        "        'category_accuracy': category_matches / len(df_test) * 100\n",
        "    }\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RETRIEVAL-ONLY RESULTS (ALL QUERIES)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n{'K':<5} {'Intent Match':<15} {'Category Match':<15}\")\n",
        "print(\"-\" * 70)\n",
        "for k, metrics in results.items():\n",
        "    print(f\"{k:<5} {metrics['intent_accuracy']:>6.2f}%        {metrics['category_accuracy']:>6.2f}%\")\n",
        "\n",
        "# Break down by query type\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BREAKDOWN BY QUERY TYPE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Deterministic queries only\n",
        "df_test_det = df_test[df_test['label'] == 0]\n",
        "test_det_embeddings = embedding_model.encode(\n",
        "    df_test_det['instruction'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "distances_det, indices_det = full_index.search(test_det_embeddings.astype('float32'), 1)\n",
        "det_intent_matches = 0\n",
        "for i, test_row in df_test_det.iterrows():\n",
        "    retrieved_idx = indices_det[df_test_det.index.get_loc(i)][0]\n",
        "    if df_train.iloc[retrieved_idx]['intent'] == test_row['intent']:\n",
        "        det_intent_matches += 1\n",
        "\n",
        "print(f\"\\nDeterministic queries ({len(df_test_det)} queries):\")\n",
        "print(f\"  Top-1 Intent Match: {det_intent_matches/len(df_test_det)*100:.2f}%\")\n",
        "\n",
        "# Indeterministic queries only\n",
        "df_test_indet = df_test[df_test['label'] == 1]\n",
        "test_indet_embeddings = embedding_model.encode(\n",
        "    df_test_indet['instruction'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "distances_indet, indices_indet = full_index.search(test_indet_embeddings.astype('float32'), 1)\n",
        "indet_intent_matches = 0\n",
        "for i, test_row in df_test_indet.iterrows():\n",
        "    retrieved_idx = indices_indet[df_test_indet.index.get_loc(i)][0]\n",
        "    if df_train.iloc[retrieved_idx]['intent'] == test_row['intent']:\n",
        "        indet_intent_matches += 1\n",
        "\n",
        "print(f\"\\nIndeterministic queries ({len(df_test_indet)} queries):\")\n",
        "print(f\"  Top-1 Intent Match: {indet_intent_matches/len(df_test_indet)*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY INSIGHT:\")\n",
        "print(\"=\"*70)\n",
        "print(\"This shows how well PURE RETRIEVAL works when forced to handle\")\n",
        "print(\"BOTH deterministic (good fit) AND indeterministic (poor fit) queries.\")\n",
        "print(\"\\nExpected: Deterministic does well, Indeterministic does poorly.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"QUICK TEST: RETRIEVAL vs LLM (10 examples)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "_, df_temp = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
        "_, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, stratify=df_temp['label'])\n",
        "df_train, _ = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Get 10 indeterministic test queries\n",
        "df_test_indet = df_test[df_test['label'] == 1].sample(n=10, random_state=42)\n",
        "\n",
        "print(f\"\\nTesting on 10 indeterministic queries\\n\")\n",
        "\n",
        "# Load models\n",
        "print(\"Loading models...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Build retrieval index\n",
        "train_embeddings = embedding_model.encode(df_train['instruction'].tolist(), show_progress_bar=False, convert_to_numpy=True)\n",
        "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "index.add(train_embeddings.astype('float32'))\n",
        "\n",
        "# Load LLM\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\", device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.float16\n",
        ")\n",
        "llm_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\")\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\")\n",
        "\n",
        "print(\"‚úì Models loaded\\n\")\n",
        "\n",
        "# Test each query\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "retrieval_scores = []\n",
        "llm_scores = []\n",
        "\n",
        "for idx, row in df_test_indet.iterrows():\n",
        "    query = row['instruction']\n",
        "    reference = row['response']\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Retrieval\n",
        "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n",
        "    dist, ind = index.search(query_emb.astype('float32'), 1)\n",
        "    retrieved_resp = df_train.iloc[ind[0][0]]['response']\n",
        "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"\\nRetrieval (ROUGE-L: {ret_score:.3f}):\")\n",
        "    print(f\"{retrieved_resp[:150]}...\")\n",
        "\n",
        "    # LLM\n",
        "    prompt = f\"Customer: {query}\\nAssistant:\"\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(**inputs, max_new_tokens=150, do_sample=True, temperature=0.7, pad_token_id=llm_tokenizer.eos_token_id)\n",
        "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
        "    llm_score = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"\\nLLM (ROUGE-L: {llm_score:.3f}):\")\n",
        "    print(f\"{llm_resp[:150]}...\")\n",
        "\n",
        "    winner = \"üî• LLM\" if llm_score > ret_score else \"üìö Retrieval\" if ret_score > llm_score else \"ü§ù Tie\"\n",
        "    print(f\"\\n{winner} wins (Œî {abs(llm_score - ret_score):.3f})\")\n",
        "\n",
        "    retrieval_scores.append(ret_score)\n",
        "    llm_scores.append(llm_score)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY (10 examples)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Retrieval avg ROUGE-L: {np.mean(retrieval_scores):.4f}\")\n",
        "print(f\"LLM avg ROUGE-L:       {np.mean(llm_scores):.4f}\")\n",
        "\n",
        "if np.mean(llm_scores) > np.mean(retrieval_scores):\n",
        "    print(\"\\n‚úÖ LLM generates better responses!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Retrieval matches/beats LLM!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32432db100c04db3956c6e445a79eeb1",
            "857dcc2a21b74fd5bb9680340e69b01d",
            "907944dbeedc46c0a4fee5d681090870",
            "e2106c9b78994b9f8ded9fc582261c76",
            "f7c436c647bd4fa78f35513b532607f0",
            "19f9994a649b4d1aaebec84b8746e5d7",
            "11507524289345b6affbc4085098f2ee",
            "1135b2d879484da48614202dae8d9dab",
            "60ae00fccc61461199b79689985fb832",
            "3500b3422a024ea780c988e0ceccaf8f",
            "c6930ac6fd294cf2bdd559d96778bf98"
          ]
        },
        "id": "GL-5nAGeFBNL",
        "outputId": "109fd8f5-5665-4808-d5bc-0270abeb3f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "QUICK TEST: RETRIEVAL vs LLM (10 examples)\n",
            "======================================================================\n",
            "\n",
            "Testing on 10 indeterministic queries\n",
            "\n",
            "Loading models...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32432db100c04db3956c6e445a79eeb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Models loaded\n",
            "\n",
            "======================================================================\n",
            "Query: canceling platinum account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.389):\n",
            "Thank you for reaching out about canceling your {{Account Category}} account. I understand that you are looking to close your account, and I'm here to...\n",
            "\n",
            "LLM (ROUGE-L: 0.281):\n",
            "I'm here to assist you in canceling your {{Account Type}} account. I understand that you may have made a change of heart or have a specific reason for...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.108)\n",
            "======================================================================\n",
            "Query: I want assistance to close my {{Account Type}} account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.346):\n",
            "Thank you for your message to us for assistance with closing your {{Account Type}} account. I understand that you have made this decision, and I am he...\n",
            "\n",
            "LLM (ROUGE-L: 0.287):\n",
            "I'm here to provide you with the assistance you need to close your {{Account Type}} account! I understand that it may not be an easy decision, but I'm...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.059)\n",
            "======================================================================\n",
            "Query: I try to delete a fucking standard account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.335):\n",
            "Happy to get your message to us regarding the deletion of your standard account. I understand that this is an important decision for you, and I'm here...\n",
            "\n",
            "LLM (ROUGE-L: 0.209):\n",
            "I appreciate your initiative to delete your {{Account Type}} account. I'm here to assist you with this process. To proceed, I kindly request you to fo...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.127)\n",
            "======================================================================\n",
            "Query: i need assistance to send my feedback aboutur company\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.441):\n",
            "Thank you for choosing to share your feedback with us! We greatly appreciate your willingness to provide valuable insights about your experience with ...\n",
            "\n",
            "LLM (ROUGE-L: 0.245):\n",
            "I'm thrilled that you're seeking assistance to send your valuable feedback about our company! Your feedback plays a crucial role in helping us improve...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.195)\n",
            "======================================================================\n",
            "Query: I am looking for information about a password retrieval\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.375):\n",
            "For sure! I'm here to provide you with all the necessary information about password retrieval. Understanding the process and having all the facts is e...\n",
            "\n",
            "LLM (ROUGE-L: 0.163):\n",
            "I'm thrilled to assist you in retrieving the information you seek regarding your password. To ensure that I can address your request accurately, could...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.212)\n",
            "======================================================================\n",
            "Query: I don't know how I could remove the platinum account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.441):\n",
            "Thank you for reaching out about removing your {{Account Category}} account. I understand that you may be unsure about the process, and I'm here to as...\n",
            "\n",
            "LLM (ROUGE-L: 0.321):\n",
            "I'm here to help you remove your platinum account with us. I understand that you're unsure about the process, and I want to assure you that it's a str...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.120)\n",
            "======================================================================\n",
            "Query: problem with {{Account Category}} account removals\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.506):\n",
            "I'm sorry to hear that you're experiencing problems with removing your {{Account Category}} account. Our team is committed to resolving any issues you...\n",
            "\n",
            "LLM (ROUGE-L: 0.400):\n",
            "I see that you are experiencing some difficulties with the removal of your {{Account Category}} account. I understand how important it is for you to h...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.106)\n",
            "======================================================================\n",
            "Query: I do not know how to reset my profile key\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.331):\n",
            "I see that you're unsure about how to reset the key to your profile. No worries, I'm here to help guide you through the process!\n",
            "\n",
            "To reset your profil...\n",
            "\n",
            "LLM (ROUGE-L: 0.214):\n",
            "Welcome to our platform! I'm here to help you with resetting your profile key. To begin with, let's ensure we're on the right track. Could you please ...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.117)\n",
            "======================================================================\n",
            "Query: where do I open a standard account?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.320):\n",
            "Thank you for your interest in creating a standard account with us! To create a standard account, you can visit our website at {{Website URL}}, where ...\n",
            "\n",
            "LLM (ROUGE-L: 0.092):\n",
            "I appreciate your eagerness to open a standard account...\n",
            "\n",
            "üìö Retrieval wins (Œî 0.228)\n",
            "======================================================================\n",
            "Query: purchase {{Order Number}} status\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval (ROUGE-L: 0.255):\n",
            "Appreciate your message to inquire about the status of your purchase with the purchase number {{Order Number}}. I'm here to provide you with the infor...\n",
            "\n",
            "LLM (ROUGE-L: 0.409):\n",
            "I'm glad you're interested in checking the status of your purchase with the order number {{Order Number}}. Our team is working diligently to process y...\n",
            "\n",
            "üî• LLM wins (Œî 0.154)\n",
            "\n",
            "======================================================================\n",
            "SUMMARY (10 examples)\n",
            "======================================================================\n",
            "Retrieval avg ROUGE-L: 0.3740\n",
            "LLM avg ROUGE-L:       0.2622\n",
            "\n",
            "‚ö†Ô∏è  Retrieval matches/beats LLM!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FAIR TEST: Retrieval (500) vs LLM (trained on same 500)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "\n",
        "# Get the EXACT 500 examples used for LLM training\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "\n",
        "# Split: 90% train, 10% val (same as LLM training)\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train_pilot, df_val_pilot = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining data: {len(df_train_pilot)} examples\")\n",
        "print(f\"Validation data: {len(df_val_pilot)} examples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Building retrieval index with ONLY 450 training examples\")\n",
        "print(\"(same data LLM was trained on)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Build retrieval index with ONLY the 450 training examples\n",
        "train_embeddings = embedding_model.encode(\n",
        "    df_train_pilot['instruction'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "index.add(train_embeddings.astype('float32'))\n",
        "\n",
        "print(f\"‚úì Index built with {index.ntotal} examples\")\n",
        "\n",
        "# Load LLM (trained on same 450 examples)\n",
        "print(\"\\nLoading LLM (trained on same 450 examples)...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "llm_model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "print(\"‚úì LLM loaded\")\n",
        "\n",
        "# Test on validation set (50 examples)\n",
        "print(f\"\\nTesting on {len(df_val_pilot)} validation examples...\")\n",
        "\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "retrieval_scores = []\n",
        "llm_scores = []\n",
        "results = []\n",
        "\n",
        "for idx, row in df_val_pilot.iterrows():\n",
        "    query = row['instruction']\n",
        "    reference = row['response']\n",
        "\n",
        "    # Retrieval from 450 examples\n",
        "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n",
        "    dist, ind = index.search(query_emb.astype('float32'), 1)\n",
        "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n",
        "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n",
        "\n",
        "    # LLM generation\n",
        "    prompt = f\"Customer: {query}\\nAssistant:\"\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id\n",
        "        )\n",
        "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
        "    llm_score = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n",
        "\n",
        "    retrieval_scores.append(ret_score)\n",
        "    llm_scores.append(llm_score)\n",
        "\n",
        "    results.append({\n",
        "        'query': query,\n",
        "        'reference': reference[:100],\n",
        "        'retrieval': retrieved_resp[:100],\n",
        "        'llm': llm_resp[:100],\n",
        "        'ret_score': ret_score,\n",
        "        'llm_score': llm_score,\n",
        "        'winner': 'LLM' if llm_score > ret_score else 'Retrieval'\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FAIR COMPARISON RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nRetrieval (from 450 examples): {np.mean(retrieval_scores):.4f} ROUGE-L\")\n",
        "print(f\"LLM (trained on 450 examples):  {np.mean(llm_scores):.4f} ROUGE-L\")\n",
        "\n",
        "diff = np.mean(llm_scores) - np.mean(retrieval_scores)\n",
        "print(f\"\\nDifference: {diff:+.4f} ({'LLM' if diff > 0 else 'Retrieval'} better)\")\n",
        "\n",
        "llm_wins = sum([1 for r in results if r['winner'] == 'LLM'])\n",
        "ret_wins = sum([1 for r in results if r['winner'] == 'Retrieval'])\n",
        "\n",
        "print(f\"\\nHead-to-head: LLM wins {llm_wins}/50, Retrieval wins {ret_wins}/50\")\n",
        "\n",
        "# Statistical significance\n",
        "from scipy import stats\n",
        "t_stat, p_value = stats.ttest_rel(llm_scores, retrieval_scores)\n",
        "print(f\"\\nPaired t-test: t={t_stat:.3f}, p={p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(f\"‚úì Difference is statistically significant (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"‚úó Difference is NOT statistically significant (p >= 0.05)\")\n",
        "\n",
        "# Show examples\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE COMPARISONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i in range(min(5, len(results))):\n",
        "    r = results[i]\n",
        "    print(f\"\\nQuery: {r['query']}\")\n",
        "    print(f\"Retrieval ({r['ret_score']:.3f}): {r['retrieval']}...\")\n",
        "    print(f\"LLM ({r['llm_score']:.3f}):       {r['llm']}...\")\n",
        "    print(f\"Winner: {r['winner']}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if diff > 0.02:\n",
        "    print(\"‚úÖ LLM generates BETTER responses than retrieval\")\n",
        "    print(\"   Even with same training data, LLM learns patterns and generalizes!\")\n",
        "    print(\"   ‚Üí Hybrid approach JUSTIFIED\")\n",
        "elif diff < -0.02:\n",
        "    print(\"‚ö†Ô∏è  Retrieval gives BETTER responses than LLM\")\n",
        "    print(\"   With only 450 examples, retrieval's exact matching beats LLM\")\n",
        "    print(\"   ‚Üí Need more training data for LLM to beat retrieval\")\n",
        "else:\n",
        "    print(\"‚âà  LLM and Retrieval are COMPARABLE\")\n",
        "    print(\"   With limited data (450 examples), both perform similarly\")\n",
        "    print(\"   ‚Üí LLM advantage may emerge with more training data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9293f9f9f43547fa97526b2f05a0ce86",
            "38e8e1ef2a16403f98b5830e76d33e9c",
            "e1a0d8b74cf046b2a6255a25f49dad42",
            "6a1eedab5adb439db9e0f469689b6106",
            "6853adb4f0074180afda0e7ed26c7721",
            "7c02c10581ed4f3796e8928207e1c71e",
            "406f731d39dd42bdb3ed630ba3cd995c",
            "2b04e17217074763b5b1c8951909b3e6",
            "75668a39f3394485baa90ac0916ad8f1",
            "ca6ee4ac8ff94379b82570183b7e8885",
            "849ca1fb0f3b4936b8d6513eae3d6789",
            "2a7293f104504eafa7d997447ad5a673",
            "dfcf9511fd77420a904cb44cf762ea5e",
            "ce5b8ba061e14ef291a20b5f62d22e42",
            "ff6d55f4bbbc420c94f07ed554af5d02",
            "f34b087519f94c478e06963e60bba867",
            "036128786b0d4abb827ca142c084ea6f",
            "284e03ddba8149dbbc74081940530ce7",
            "b2c9a27ea00d442bbee4091a9d98db95",
            "c5528c89943143c9898e6cfbdda0a15d",
            "ed84889967af4a9082c731cd86a32bd9",
            "d5af533a725c4499a5cd34d1d04c7723"
          ]
        },
        "id": "J3ADzbzDGFGh",
        "outputId": "cdaa1c4c-7a9e-4a98-a243-677e53d7d5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FAIR TEST: Retrieval (500) vs LLM (trained on same 500)\n",
            "======================================================================\n",
            "\n",
            "Training data: 450 examples\n",
            "Validation data: 50 examples\n",
            "\n",
            "======================================================================\n",
            "Building retrieval index with ONLY 450 training examples\n",
            "(same data LLM was trained on)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9293f9f9f43547fa97526b2f05a0ce86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Index built with 450 examples\n",
            "\n",
            "Loading LLM (trained on same 450 examples)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7293f104504eafa7d997447ad5a673"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì LLM loaded\n",
            "\n",
            "Testing on 50 validation examples...\n",
            "\n",
            "======================================================================\n",
            "FAIR COMPARISON RESULTS\n",
            "======================================================================\n",
            "\n",
            "Retrieval (from 450 examples): 0.3474 ROUGE-L\n",
            "LLM (trained on 450 examples):  0.2887 ROUGE-L\n",
            "\n",
            "Difference: -0.0587 (Retrieval better)\n",
            "\n",
            "Head-to-head: LLM wins 18/50, Retrieval wins 32/50\n",
            "\n",
            "Paired t-test: t=-3.489, p=0.0010\n",
            "‚úì Difference is statistically significant (p < 0.05)\n",
            "\n",
            "======================================================================\n",
            "SAMPLE COMPARISONS\n",
            "======================================================================\n",
            "\n",
            "Query: help me check the eta of the order {{Order Number}}\n",
            "Retrieval (0.447): We're here for you! I'm aware that you need assistance in checking the estimated time of arrival (ET...\n",
            "LLM (0.341):       Sure thing! I understand your eagerness to check the estimated expiration date of your order with th...\n",
            "Winner: Retrieval\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Query: can ya help me to open an platinum account\n",
            "Retrieval (0.145): Indeed! I admire your interest in utilizing the exclusive advantages of our {{Account Category}} acc...\n",
            "LLM (0.222):       Of course, I'd be more than happy to assist you in opening a platinum account! Rest assured, the pro...\n",
            "Winner: LLM\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Query: I don't know hwat to do to earn several items\n",
            "Retrieval (0.248): That's wonderful to hear that you're interested in earning one of our items! We have various program...\n",
            "LLM (0.222):       Thank you for reaching out! I'm sorry to hear that you have concerns about the quality of the items ...\n",
            "Winner: Retrieval\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Query: can uhelp me lodge a customer complaint\n",
            "Retrieval (0.330): I truly empathize with your situation and I'm sorry to hear that you're seeking assistance to file a...\n",
            "LLM (0.324):       Of course, I'm here to assist you in lodging a customer complaint! I'm deeply sorry for any dissatis...\n",
            "Winner: Retrieval\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Query: want help closing the  standard account\n",
            "Retrieval (0.429): We're here for you regarding the closure of your standard account. I understand that closing an acco...\n",
            "LLM (0.298):       I'm here to help you with closing your {{Account Type}} account. I understand that you have decided ...\n",
            "Winner: Retrieval\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "INTERPRETATION\n",
            "======================================================================\n",
            "‚ö†Ô∏è  Retrieval gives BETTER responses than LLM\n",
            "   With only 450 examples, retrieval's exact matching beats LLM\n",
            "   ‚Üí Need more training data for LLM to beat retrieval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FAIR OOD TEST: Retrieval (450) vs LLM (450)\")\n",
        "print(\"Testing on validation queries NOT seen during training\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data - get the EXACT same split\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "\n",
        "# Same split as training\n",
        "df_train_pilot, df_val_pilot = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining: {len(df_train_pilot)} examples (both systems trained on these)\")\n",
        "print(f\"Validation: {len(df_val_pilot)} examples (OOD - not seen during training)\")\n",
        "\n",
        "# Pick 10 diverse queries from validation set\n",
        "print(\"\\nSelecting 10 diverse OOD queries from validation set...\")\n",
        "\n",
        "# Get examples from different intents for diversity\n",
        "val_intents = df_val_pilot['intent'].unique()\n",
        "print(f\"Available intents in validation: {val_intents}\")\n",
        "\n",
        "# Sample 2 from each of 5 different intents (or 10 random if not enough variety)\n",
        "if len(val_intents) >= 5:\n",
        "    ood_samples = []\n",
        "    for intent in list(val_intents)[:5]:\n",
        "        intent_samples = df_val_pilot[df_val_pilot['intent'] == intent].sample(n=min(2, len(df_val_pilot[df_val_pilot['intent'] == intent])), random_state=42)\n",
        "        ood_samples.append(intent_samples)\n",
        "    df_ood = pd.concat(ood_samples)\n",
        "else:\n",
        "    df_ood = df_val_pilot.sample(n=10, random_state=42)\n",
        "\n",
        "print(f\"\\nSelected 10 OOD queries:\")\n",
        "for i, row in df_ood.iterrows():\n",
        "    print(f\"  - Intent: {row['intent']}, Query: {row['instruction'][:60]}...\")\n",
        "\n",
        "# Load models\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading models...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Retrieval: Build index with ONLY 450 training examples\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(\"\\n1. Building retrieval index (450 training examples only)...\")\n",
        "train_embeddings = embedding_model.encode(\n",
        "    df_train_pilot['instruction'].tolist(),\n",
        "    show_progress_bar=False,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "index.add(train_embeddings.astype('float32'))\n",
        "print(f\"   ‚úì Index built with {index.ntotal} examples\")\n",
        "\n",
        "# LLM: Load pilot model (trained on same 450 examples)\n",
        "print(\"\\n2. Loading LLM (trained on same 450 examples)...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "llm_model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "print(\"   ‚úì LLM loaded\")\n",
        "\n",
        "# Test\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING ON 10 OOD QUERIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "retrieval_scores = []\n",
        "llm_scores = []\n",
        "\n",
        "for i, (idx, row) in enumerate(df_ood.iterrows(), 1):\n",
        "    query = row['instruction']\n",
        "    reference = row['response']\n",
        "    intent = row['intent']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Query {i}/10 - Intent: {intent}\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Retrieval\n",
        "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n",
        "    dist, ind = index.search(query_emb.astype('float32'), 1)\n",
        "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n",
        "    retrieved_query = df_train_pilot.iloc[ind[0][0]]['instruction']\n",
        "    retrieved_intent = df_train_pilot.iloc[ind[0][0]]['intent']\n",
        "\n",
        "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"\\nRetrieval:\")\n",
        "    print(f\"  Matched to: '{retrieved_query[:70]}...'\")\n",
        "    print(f\"  Matched intent: {retrieved_intent} {'‚úì' if retrieved_intent == intent else '‚úó'}\")\n",
        "    print(f\"  Distance: {dist[0][0]:.3f}\")\n",
        "    print(f\"  ROUGE-L: {ret_score:.3f}\")\n",
        "    print(f\"  Response: {retrieved_resp[:120]}...\")\n",
        "\n",
        "    # LLM\n",
        "    prompt = f\"Customer: {query}\\nAssistant:\"\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id\n",
        "        )\n",
        "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
        "    llm_score = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"\\nLLM:\")\n",
        "    print(f\"  ROUGE-L: {llm_score:.3f}\")\n",
        "    print(f\"  Response: {llm_resp[:120]}...\")\n",
        "\n",
        "    winner = \"üî• LLM\" if llm_score > ret_score else \"üìö Retrieval\" if ret_score > llm_score else \"ü§ù Tie\"\n",
        "    print(f\"\\n{winner} (Œî {abs(llm_score - ret_score):.3f})\")\n",
        "\n",
        "    retrieval_scores.append(ret_score)\n",
        "    llm_scores.append(llm_score)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FAIR OOD TEST RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nRetrieval (450 training): {np.mean(retrieval_scores):.4f} ROUGE-L\")\n",
        "print(f\"LLM (450 training):       {np.mean(llm_scores):.4f} ROUGE-L\")\n",
        "\n",
        "diff = np.mean(llm_scores) - np.mean(retrieval_scores)\n",
        "print(f\"\\nDifference: {diff:+.4f}\")\n",
        "\n",
        "llm_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if l > r])\n",
        "ret_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if r > l])\n",
        "\n",
        "print(f\"\\nHead-to-head: LLM {llm_wins}/10, Retrieval {ret_wins}/10\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if diff > 0.02:\n",
        "    print(\"‚úÖ LLM better at generalizing to unseen queries in same domain\")\n",
        "    print(\"   ‚Üí LLM learned patterns, can handle variations\")\n",
        "elif diff < -0.02:\n",
        "    print(\"‚ö†Ô∏è  Retrieval better even on unseen queries\")\n",
        "    print(\"   ‚Üí Semantic similarity matching is very effective\")\n",
        "else:\n",
        "    print(\"‚âà  Both comparable on OOD queries\")\n",
        "    print(\"   ‚Üí Limited training data (450) affects both similarly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e9946edaa30c473c963813b2c3a48a4b",
            "5d5d22abfee54fbf90ff8036bbd1fdfe",
            "807b8279540e43a4aad730f6da22c1a7",
            "d3904d5bad994f4dadf3211bd293baa9",
            "f20454fb028045a3b549e2cdb96f3e65",
            "72d14563d3024e878e4da7218957045a",
            "f17061bac1ea466f8c4cf742ee30e4c6",
            "4da6983957fa41f783b379f9b4089095",
            "e56c362dd7af445695b3a2deffe2fad2",
            "504a6dfa725a45ca9829f9048229f215",
            "52813899d2724ef18af73e88a3bf91c9"
          ]
        },
        "id": "Jf32opaSHRtm",
        "outputId": "412ff404-aa3d-4bf4-8dbb-eb57d0b404df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FAIR OOD TEST: Retrieval (450) vs LLM (450)\n",
            "Testing on validation queries NOT seen during training\n",
            "======================================================================\n",
            "\n",
            "Training: 450 examples (both systems trained on these)\n",
            "Validation: 50 examples (OOD - not seen during training)\n",
            "\n",
            "Selecting 10 diverse OOD queries from validation set...\n",
            "Available intents in validation: ['track_order' 'create_account' 'place_order' 'complaint' 'delete_account'\n",
            " 'switch_account' 'review' 'recover_password' 'change_order'\n",
            " 'registration_problems' 'edit_account' 'cancel_order']\n",
            "\n",
            "Selected 10 OOD queries:\n",
            "  - Intent: track_order, Query: ETA of purchase {{Order Number}}...\n",
            "  - Intent: track_order, Query: help me see the eta of purchase {{Order Number}}...\n",
            "  - Intent: create_account, Query: I have to open an pro account for my dad...\n",
            "  - Intent: create_account, Query: need assistance with creating a freemium account...\n",
            "  - Intent: place_order, Query: I don't know hwat to do to earn several items...\n",
            "  - Intent: place_order, Query: I am trying to shop something...\n",
            "  - Intent: complaint, Query: can uhelp me lodge a customer complaint...\n",
            "  - Intent: complaint, Query: need to lodge a fucking customer complaint...\n",
            "  - Intent: delete_account, Query: I need to remove the {{Account Type}} account...\n",
            "  - Intent: delete_account, Query: I need help closing a platinum account...\n",
            "\n",
            "======================================================================\n",
            "Loading models...\n",
            "======================================================================\n",
            "\n",
            "1. Building retrieval index (450 training examples only)...\n",
            "   ‚úì Index built with 450 examples\n",
            "\n",
            "2. Loading LLM (trained on same 450 examples)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9946edaa30c473c963813b2c3a48a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úì LLM loaded\n",
            "\n",
            "======================================================================\n",
            "TESTING ON 10 OOD QUERIES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Query 1/10 - Intent: track_order\n",
            "Query: ETA of purchase {{Order Number}}\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'see the ETA of the purchase {{Order Number}}...'\n",
            "  Matched intent: track_order ‚úì\n",
            "  Distance: 0.169\n",
            "  ROUGE-L: 0.428\n",
            "  Response: I hear you! I'm following you that you would like to check the Estimated Time of Arrival (ETA) for your purchase with th...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.335\n",
            "  Response: I completely understand your concern about the estimated time of arrival (ETA) for purchase number {{Order Number}}. You...\n",
            "\n",
            "üìö Retrieval (Œî 0.092)\n",
            "\n",
            "======================================================================\n",
            "Query 2/10 - Intent: track_order\n",
            "Query: help me see the eta of purchase {{Order Number}}\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'help me to check the eta of the purchase {{Order Number}}...'\n",
            "  Matched intent: track_order ‚úì\n",
            "  Distance: 0.072\n",
            "  ROUGE-L: 0.389\n",
            "  Response: Thank you for reaching out! I'm here to assist you with checking the estimated time of arrival (ETA) for your purchase w...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.412\n",
            "  Response: I appreciate your message, and I'm here to help you see the estimated time of completion for your purchase with the orde...\n",
            "\n",
            "üî• LLM (Œî 0.023)\n",
            "\n",
            "======================================================================\n",
            "Query 3/10 - Intent: create_account\n",
            "Query: I have to open an pro account for my dad\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'i do not know how i can open a pro account for my fiance...'\n",
            "  Matched intent: create_account ‚úì\n",
            "  Distance: 0.537\n",
            "  ROUGE-L: 0.404\n",
            "  Response: Thank you so much for reaching out to us for assistance in opening a {{Account Type}} account for your fiance. Rest assu...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.267\n",
            "  Response: We're thrilled that you're willing to assist your dad in opening a pro account! Your involvement will not only ensure a ...\n",
            "\n",
            "üìö Retrieval (Œî 0.137)\n",
            "\n",
            "======================================================================\n",
            "Query 4/10 - Intent: create_account\n",
            "Query: need assistance with creating a freemium account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I want to change to the freemium account, can you help me?...'\n",
            "  Matched intent: switch_account ‚úó\n",
            "  Distance: 0.463\n",
            "  ROUGE-L: 0.196\n",
            "  Response: Indeed! I'm delighted to assist you with switching to the freemium account and making the most of its features:\n",
            "\n",
            "1. **Si...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.300\n",
            "  Response: Of course! I'm here to assist you in creating your very own freemium account. Don't worry, it's a breeze and I'll guide ...\n",
            "\n",
            "üî• LLM (Œî 0.104)\n",
            "\n",
            "======================================================================\n",
            "Query 5/10 - Intent: place_order\n",
            "Query: I don't know hwat to do to earn several items\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'need assistance to earn an item...'\n",
            "  Matched intent: place_order ‚úì\n",
            "  Distance: 0.737\n",
            "  ROUGE-L: 0.248\n",
            "  Response: That's wonderful to hear that you're interested in earning one of our items! We have various programs and opportunities ...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.227\n",
            "  Response: I'm glad to hear from you! I understand that you're eager to earn several items on our platform. Don't worry, I'm here t...\n",
            "\n",
            "üìö Retrieval (Œî 0.021)\n",
            "\n",
            "======================================================================\n",
            "Query 6/10 - Intent: place_order\n",
            "Query: I am trying to shop something\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I need help to shop a product...'\n",
            "  Matched intent: place_order ‚úì\n",
            "  Distance: 0.382\n",
            "  ROUGE-L: 0.248\n",
            "  Response: Thank you for contacting to us for assistance with shopping a product! We are here to guide you through the process and ...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.278\n",
            "  Response: I'm thrilled to help you with shopping! How can I assist you further? To make our shopping experience even better, could...\n",
            "\n",
            "üî• LLM (Œî 0.030)\n",
            "\n",
            "======================================================================\n",
            "Query 7/10 - Intent: complaint\n",
            "Query: can uhelp me lodge a customer complaint\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'can you help me file a customer complaint?...'\n",
            "  Matched intent: complaint ‚úì\n",
            "  Distance: 0.436\n",
            "  ROUGE-L: 0.330\n",
            "  Response: I truly empathize with your situation and I'm sorry to hear that you're seeking assistance to file a customer complaint....\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.288\n",
            "  Response: I appreciate your inquiry and I'm here to assist you with lodging your customer complaint. Our top priority is your sati...\n",
            "\n",
            "üìö Retrieval (Œî 0.042)\n",
            "\n",
            "======================================================================\n",
            "Query 8/10 - Intent: complaint\n",
            "Query: need to lodge a fucking customer complaint\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I have got to lodge a customer complaint, help me...'\n",
            "  Matched intent: complaint ‚úì\n",
            "  Distance: 0.316\n",
            "  ROUGE-L: 0.465\n",
            "  Response: I'm truly sorry to hear that you need to lodge a customer complaint against our company. Your feedback is valuable to us...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.264\n",
            "  Response: I apologize if you are not happy with your experience and feel the need to lodge a customer complaint. It is important t...\n",
            "\n",
            "üìö Retrieval (Œî 0.201)\n",
            "\n",
            "======================================================================\n",
            "Query 9/10 - Intent: delete_account\n",
            "Query: I need to remove the {{Account Type}} account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I do not know how I could remove the {{Account Type}} account...'\n",
            "  Matched intent: delete_account ‚úì\n",
            "  Distance: 0.020\n",
            "  ROUGE-L: 0.416\n",
            "  Response: Glad you contacted to us with your question about removing your {{Account Type}} account. I understand that you're looki...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.273\n",
            "  Response: I'm thrilled to hear that you're looking to remove your {{Account Type}} account! I completely understand that you may w...\n",
            "\n",
            "üìö Retrieval (Œî 0.143)\n",
            "\n",
            "======================================================================\n",
            "Query 10/10 - Intent: delete_account\n",
            "Query: I need help closing a platinum account\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I have got to close the platinum account, help me...'\n",
            "  Matched intent: delete_account ‚úì\n",
            "  Distance: 0.166\n",
            "  ROUGE-L: 0.318\n",
            "  Response: Grateful you reached out about closing your {{Account Category}} account. I understand that you need assistance with thi...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.106\n",
            "  Response: I'm glad you've reached out for assistance with closing your...\n",
            "\n",
            "üìö Retrieval (Œî 0.212)\n",
            "\n",
            "======================================================================\n",
            "FAIR OOD TEST RESULTS\n",
            "======================================================================\n",
            "\n",
            "Retrieval (450 training): 0.3441 ROUGE-L\n",
            "LLM (450 training):       0.2750 ROUGE-L\n",
            "\n",
            "Difference: -0.0691\n",
            "\n",
            "Head-to-head: LLM 3/10, Retrieval 7/10\n",
            "\n",
            "======================================================================\n",
            "INTERPRETATION\n",
            "======================================================================\n",
            "‚ö†Ô∏è  Retrieval better even on unseen queries\n",
            "   ‚Üí Semantic similarity matching is very effective\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "df_train_pilot, _ = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COVERAGE ANALYSIS: What's in the 450 training examples?\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nFull indeterministic dataset: {len(df_indet):,} examples\")\n",
        "print(f\"Pilot training set: {len(df_train_pilot)} examples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTENT COVERAGE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Full dataset intent distribution\n",
        "full_intents = df_indet['intent'].value_counts()\n",
        "print(f\"\\nFull dataset has {len(full_intents)} unique intents:\")\n",
        "print(full_intents)\n",
        "\n",
        "# Pilot training set intent distribution\n",
        "pilot_intents = df_train_pilot['intent'].value_counts()\n",
        "print(f\"\\n\\nPilot training has {len(pilot_intents)} intents covered:\")\n",
        "print(pilot_intents)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MISSING/UNDERREPRESENTED INTENTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Which intents are missing or sparse?\n",
        "for intent, count in full_intents.items():\n",
        "    pilot_count = pilot_intents.get(intent, 0)\n",
        "    coverage = (pilot_count / count * 100) if count > 0 else 0\n",
        "\n",
        "    if pilot_count == 0:\n",
        "        print(f\"‚ùå MISSING: {intent} (0/{count} examples, 0% coverage)\")\n",
        "    elif coverage < 5:\n",
        "        print(f\"‚ö†Ô∏è  SPARSE: {intent} ({pilot_count}/{count} examples, {coverage:.1f}% coverage)\")\n",
        "    elif coverage < 20:\n",
        "        print(f\"‚ö†Ô∏è  LOW: {intent} ({pilot_count}/{count} examples, {coverage:.1f}% coverage)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WHAT THIS MEANS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "The 450 examples are NOT gold standard!\n",
        "\n",
        "‚úì For intents well-represented in 450: Retrieval works great\n",
        "‚úó For missing/sparse intents: Retrieval will fail badly\n",
        "‚úó For novel query patterns: No close matches exist\n",
        "\n",
        "This is why validation queries (from same 500 sample) had good matches,\n",
        "but queries from underrepresented intents would score poorly.\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REAL-WORLD IMPLICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "If you deployed this 450-example retrieval system:\n",
        "- Queries similar to the {len(pilot_intents)} covered intents: WORKS\n",
        "- Queries from missing intents: FAILS (large distances, poor matches)\n",
        "- Novel variations: FAILS (no semantic match)\n",
        "\n",
        "This is exactly why LLMs are valuable in real-world scenarios:\n",
        "‚Üí They can generalize to sparse/missing data\n",
        "‚Üí Retrieval needs COMPREHENSIVE coverage to work (like full Bitext)\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9DodGLtKFN7",
        "outputId": "3b0f38b5-c30b-406c-e8f4-c02a0f89ebb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COVERAGE ANALYSIS: What's in the 450 training examples?\n",
            "======================================================================\n",
            "\n",
            "Full indeterministic dataset: 11,971 examples\n",
            "Pilot training set: 450 examples\n",
            "\n",
            "======================================================================\n",
            "INTENT COVERAGE\n",
            "======================================================================\n",
            "\n",
            "Full dataset has 12 unique intents:\n",
            "intent\n",
            "complaint                1000\n",
            "switch_account           1000\n",
            "edit_account             1000\n",
            "registration_problems     999\n",
            "place_order               998\n",
            "cancel_order              998\n",
            "create_account            997\n",
            "review                    997\n",
            "change_order              997\n",
            "delete_account            995\n",
            "track_order               995\n",
            "recover_password          995\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Pilot training has 12 intents covered:\n",
            "intent\n",
            "place_order              44\n",
            "switch_account           44\n",
            "delete_account           43\n",
            "registration_problems    42\n",
            "track_order              39\n",
            "recover_password         38\n",
            "complaint                38\n",
            "change_order             38\n",
            "cancel_order             35\n",
            "create_account           34\n",
            "edit_account             29\n",
            "review                   26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "======================================================================\n",
            "MISSING/UNDERREPRESENTED INTENTS\n",
            "======================================================================\n",
            "‚ö†Ô∏è  SPARSE: complaint (38/1000 examples, 3.8% coverage)\n",
            "‚ö†Ô∏è  SPARSE: switch_account (44/1000 examples, 4.4% coverage)\n",
            "‚ö†Ô∏è  SPARSE: edit_account (29/1000 examples, 2.9% coverage)\n",
            "‚ö†Ô∏è  SPARSE: registration_problems (42/999 examples, 4.2% coverage)\n",
            "‚ö†Ô∏è  SPARSE: place_order (44/998 examples, 4.4% coverage)\n",
            "‚ö†Ô∏è  SPARSE: cancel_order (35/998 examples, 3.5% coverage)\n",
            "‚ö†Ô∏è  SPARSE: create_account (34/997 examples, 3.4% coverage)\n",
            "‚ö†Ô∏è  SPARSE: review (26/997 examples, 2.6% coverage)\n",
            "‚ö†Ô∏è  SPARSE: change_order (38/997 examples, 3.8% coverage)\n",
            "‚ö†Ô∏è  SPARSE: delete_account (43/995 examples, 4.3% coverage)\n",
            "‚ö†Ô∏è  SPARSE: track_order (39/995 examples, 3.9% coverage)\n",
            "‚ö†Ô∏è  SPARSE: recover_password (38/995 examples, 3.8% coverage)\n",
            "\n",
            "======================================================================\n",
            "WHAT THIS MEANS\n",
            "======================================================================\n",
            "\n",
            "The 450 examples are NOT gold standard!\n",
            "\n",
            "‚úì For intents well-represented in 450: Retrieval works great\n",
            "‚úó For missing/sparse intents: Retrieval will fail badly\n",
            "‚úó For novel query patterns: No close matches exist\n",
            "\n",
            "This is why validation queries (from same 500 sample) had good matches,\n",
            "but queries from underrepresented intents would score poorly.\n",
            "\n",
            "\n",
            "======================================================================\n",
            "REAL-WORLD IMPLICATION\n",
            "======================================================================\n",
            "\n",
            "If you deployed this 450-example retrieval system:\n",
            "- Queries similar to the 12 covered intents: WORKS\n",
            "- Queries from missing intents: FAILS (large distances, poor matches)\n",
            "- Novel variations: FAILS (no semantic match)\n",
            "\n",
            "This is exactly why LLMs are valuable in real-world scenarios:\n",
            "‚Üí They can generalize to sparse/missing data\n",
            "‚Üí Retrieval needs COMPREHENSIVE coverage to work (like full Bitext)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STRESS TEST: Sparse Intents with Novel Wordings\")\n",
        "print(\"Testing on review (26 examples) & edit_account (29 examples)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load models first\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "df_train_pilot, _ = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "# Show what's actually in training for these intents\n",
        "print(\"\\nTraining examples for sparse intents:\")\n",
        "print(f\"  review: {len(df_train_pilot[df_train_pilot['intent']=='review'])} examples\")\n",
        "print(f\"  edit_account: {len(df_train_pilot[df_train_pilot['intent']=='edit_account'])} examples\")\n",
        "\n",
        "print(\"\\nSample training queries for 'review':\")\n",
        "for q in df_train_pilot[df_train_pilot['intent']=='review']['instruction'].head(3):\n",
        "    print(f\"  - {q}\")\n",
        "\n",
        "print(\"\\nSample training queries for 'edit_account':\")\n",
        "for q in df_train_pilot[df_train_pilot['intent']=='edit_account']['instruction'].head(3):\n",
        "    print(f\"  - {q}\")\n",
        "\n",
        "# Create 10 NOVEL queries with completely different wording\n",
        "novel_queries = [\n",
        "    # review intent - novel wordings\n",
        "    {\n",
        "        'query': \"I'd like to share my thoughts about the product quality and service I received\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Thank you for your willingness to share your thoughts about the product quality and service you received. We greatly value your feedback as it helps us improve our offerings and customer experience. To submit your review, you can visit our website and navigate to the product page, where you'll find a review section. Alternatively, you can reply to your order confirmation email with your feedback. We appreciate you taking the time to share your experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Where can I write about my experience with your company?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"We're thrilled that you want to share your experience with our company! Customer feedback is incredibly valuable to us. You can write about your experience in several ways: 1) On our website's review section, 2) Reply to your order confirmation email, 3) Through our social media pages, or 4) On third-party review platforms. Which method would be most convenient for you? We look forward to hearing about your experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"The shipping was fast but the product didn't meet my expectations - how do I let you know?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Thank you for sharing this feedback with us, and I apologize that the product didn't meet your expectations despite our fast shipping. Your honest feedback is important to us. To formally submit your review, you can visit the product page on our website and leave a detailed review there. This helps both us and other customers. Additionally, I'd like to understand more about what didn't meet your expectations - could you provide more details so we can address this?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"I want to give you guys a 5-star rating, what's the best way to do that?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"We're absolutely delighted to hear you want to give us a 5-star rating! Your positive feedback means the world to us. The best ways to leave your rating are: 1) On our website's product or service page, 2) Through the review link in your order confirmation email, 3) On Google Reviews or other review platforms you prefer. Your 5-star rating will help other customers discover our services. Thank you so much for taking the time to share your positive experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Can I post feedback about both the product and customer service in one place?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Absolutely! We encourage comprehensive feedback that covers both product and customer service experience. You can post combined feedback on our website's review section, where you can rate and comment on multiple aspects of your experience. This holistic feedback is incredibly valuable as it gives us a complete picture of your customer journey. Feel free to be as detailed as you'd like - we read every review carefully!\"\n",
        "    },\n",
        "\n",
        "    # edit_account intent - novel wordings\n",
        "    {\n",
        "        'query': \"My phone number changed and I need to update it in my profile settings\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I understand you need to update your phone number in your profile settings. I'm here to help you with that. To update your phone number, please follow these steps: 1) Log in to your account, 2) Navigate to 'Profile' or 'Account Settings', 3) Find the 'Contact Information' section, 4) Click 'Edit' next to your phone number, 5) Enter your new phone number and save changes. You may receive a verification code to confirm the new number. Is there anything else you'd like to update while you're at it?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"I got married and want to change my last name on file\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"Congratulations on your marriage! I'd be happy to assist you with updating your last name on your account. To change your last name, please log in to your account and go to 'Profile Settings' or 'Personal Information'. You'll find an option to edit your name. After updating, you may need to verify this change for security purposes. If you have any documents like an invoice or payment method that also need updating with your new name, please let me know and I can guide you through that process as well!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"How do I modify the email address associated with my login?\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I can help you modify the email address associated with your login. To update your email, please follow these steps: 1) Log in to your account with your current credentials, 2) Go to 'Account Settings' or 'Profile', 3) Look for 'Email Address' or 'Login Information', 4) Click 'Edit' or 'Change Email', 5) Enter your new email address, 6) You'll receive verification emails to both old and new addresses to confirm the change. This security measure ensures your account remains protected. Let me know if you need any assistance!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Need to switch from personal to business account details - can I do that?\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I understand you'd like to update your account from personal to business account details. While you can certainly edit your account information, switching to a business account may require additional steps depending on our account types. You can start by updating your profile information in 'Account Settings' to include business details like company name, tax ID, and business address. However, if you want to access business-specific features, you might need to upgrade to a business account type. Would you like me to guide you through either process?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"The billing address I have on file is old, I need it corrected\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I can certainly help you correct your billing address. Having accurate billing information is important for smooth transactions. To update your billing address, please: 1) Log in to your account, 2) Navigate to 'Payment Methods' or 'Billing Information', 3) Find your current billing address, 4) Click 'Edit' or 'Update', 5) Enter your new billing address and save changes. Note that this may affect future orders but won't change the address on orders already placed. Would you also like to update your shipping address if it's different?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATED 10 NOVEL QUERIES\")\n",
        "print(\"=\"*70)\n",
        "print(\"These use completely different wording than training examples!\")\n",
        "\n",
        "# Load models\n",
        "print(\"\\nLoading models...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Build retrieval index with 450 examples\n",
        "train_embeddings = embedding_model.encode(\n",
        "    df_train_pilot['instruction'].tolist(),\n",
        "    show_progress_bar=False,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "index.add(train_embeddings.astype('float32'))\n",
        "\n",
        "# Load LLM\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "llm_model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "print(\"‚úì Models loaded\")\n",
        "\n",
        "# Test\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "retrieval_scores = []\n",
        "llm_scores = []\n",
        "retrieval_distances = []\n",
        "\n",
        "for i, item in enumerate(novel_queries, 1):\n",
        "    query = item['query']\n",
        "    reference = item['reference']\n",
        "    intent = item['intent']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Query {i}/10 - Intent: {intent}\")\n",
        "    print(f\"Novel Query: {query}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Retrieval\n",
        "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n",
        "    dist, ind = index.search(query_emb.astype('float32'), 1)\n",
        "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n",
        "    retrieved_query = df_train_pilot.iloc[ind[0][0]]['instruction']\n",
        "    retrieved_intent = df_train_pilot.iloc[ind[0][0]]['intent']\n",
        "\n",
        "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n",
        "    retrieval_distances.append(dist[0][0])\n",
        "\n",
        "    print(f\"\\nRetrieval:\")\n",
        "    print(f\"  Matched to: '{retrieved_query[:70]}...'\")\n",
        "    print(f\"  Matched intent: {retrieved_intent} {'‚úì' if retrieved_intent == intent else '‚úó WRONG!'}\")\n",
        "    print(f\"  Distance: {dist[0][0]:.3f} {'(VERY FAR!)' if dist[0][0] > 1.0 else '(far)' if dist[0][0] > 0.5 else '(close)'}\")\n",
        "    print(f\"  ROUGE-L: {ret_score:.3f}\")\n",
        "    print(f\"  Response: {retrieved_resp[:120]}...\")\n",
        "\n",
        "    # LLM\n",
        "    prompt = f\"Customer: {query}\\nAssistant:\"\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id\n",
        "        )\n",
        "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
        "    llm_score = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n",
        "\n",
        "    print(f\"\\nLLM:\")\n",
        "    print(f\"  ROUGE-L: {llm_score:.3f}\")\n",
        "    print(f\"  Response: {llm_resp[:120]}...\")\n",
        "\n",
        "    winner = \"üî• LLM\" if llm_score > ret_score else \"üìö Retrieval\" if ret_score > llm_score else \"ü§ù Tie\"\n",
        "    print(f\"\\n{winner} (Œî {abs(llm_score - ret_score):.3f})\")\n",
        "\n",
        "    retrieval_scores.append(ret_score)\n",
        "    llm_scores.append(llm_score)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STRESS TEST RESULTS: Novel Queries on Sparse Intents\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nRetrieval (26-29 examples/intent): {np.mean(retrieval_scores):.4f} ROUGE-L\")\n",
        "print(f\"LLM (trained on same data):        {np.mean(llm_scores):.4f} ROUGE-L\")\n",
        "print(f\"\\nAverage retrieval distance: {np.mean(retrieval_distances):.3f}\")\n",
        "print(f\"  (Higher = worse matches, <0.5 is good, >1.0 is bad)\")\n",
        "\n",
        "diff = np.mean(llm_scores) - np.mean(retrieval_scores)\n",
        "print(f\"\\nDifference: {diff:+.4f}\")\n",
        "\n",
        "llm_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if l > r])\n",
        "ret_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if r > l])\n",
        "\n",
        "print(f\"\\nHead-to-head: LLM {llm_wins}/10, Retrieval {ret_wins}/10\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY INSIGHT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if diff > 0.05:\n",
        "    print(\"‚úÖ LLM DOMINATES on novel queries with sparse training data!\")\n",
        "    print(\"   ‚Üí With only 26-29 examples, retrieval can't find good matches\")\n",
        "    print(\"   ‚Üí LLM learned patterns and can generalize\")\n",
        "    print(\"   ‚Üí THIS IS THE VALUE OF THE HYBRID APPROACH!\")\n",
        "else:\n",
        "    print(\"   Results may vary - check individual distances\")\n",
        "\n",
        "print(\"\\nThis demonstrates:\")\n",
        "print(\"  ‚Ä¢ Retrieval needs comprehensive coverage (like full Bitext)\")\n",
        "print(\"  ‚Ä¢ LLM excels with sparse data (like real-world scenarios)\")\n",
        "print(\"  ‚Ä¢ Hybrid approach = best of both worlds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1867c501f9124cdfa82913dd3f087bb0",
            "73b0c6622a3f45ad8103584f1b777acb",
            "f710b775127e4a6e9acbee492865de16",
            "1f2b9269e0c64fcfa50f6bf514200bad",
            "829881571df74cb597ff6d8c56514673",
            "ebaaee914d7a45d8ba137caee7aa63b1",
            "2e17fa1887e94f8e817ec9a66fffdd4c",
            "294c9e5f29244c79a1fad8f06f421337",
            "fd642cfe01cd403d8858d953dec76651",
            "5b4f7f77bc5644039f832d24a8ef2ffe",
            "a578ac4a29c94d57b64bdce98a0f3a10"
          ]
        },
        "id": "iKOg7ylXMBjw",
        "outputId": "8a750827-70a3-4595-b5e8-41aa79d2a205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STRESS TEST: Sparse Intents with Novel Wordings\n",
            "Testing on review (26 examples) & edit_account (29 examples)\n",
            "======================================================================\n",
            "\n",
            "Training examples for sparse intents:\n",
            "  review: 26 examples\n",
            "  edit_account: 29 examples\n",
            "\n",
            "Sample training queries for 'review':\n",
            "  - I don't know how I can submit some feedback about a product\n",
            "  - I don't know how to write a review about a service\n",
            "  - assistance submitting feedback for ur services\n",
            "\n",
            "Sample training queries for 'edit_account':\n",
            "  - updating {{Account Type}} account\n",
            "  - update info on platinum account\n",
            "  - updating informtaion on {{Account Type}} account\n",
            "\n",
            "======================================================================\n",
            "CREATED 10 NOVEL QUERIES\n",
            "======================================================================\n",
            "These use completely different wording than training examples!\n",
            "\n",
            "Loading models...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1867c501f9124cdfa82913dd3f087bb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Models loaded\n",
            "\n",
            "======================================================================\n",
            "Query 1/10 - Intent: review\n",
            "Novel Query: I'd like to share my thoughts about the product quality and service I received\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'need help to send my feedback for ur services...'\n",
            "  Matched intent: review ‚úì\n",
            "  Distance: 0.752 (far)\n",
            "  ROUGE-L: 0.238\n",
            "  Response: We've received your message and expressing your desire to send feedback about our services! Your input is highly valuabl...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.422\n",
            "  Response: We sincerely appreciate your openness to share your thoughts about the product quality and service you received. Your fe...\n",
            "\n",
            "üî• LLM (Œî 0.183)\n",
            "\n",
            "======================================================================\n",
            "Query 2/10 - Intent: review\n",
            "Novel Query: Where can I write about my experience with your company?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'need to write a review about ur company how can i do it...'\n",
            "  Matched intent: review ‚úì\n",
            "  Distance: 0.801 (far)\n",
            "  ROUGE-L: 0.279\n",
            "  Response: Thank you for your interest in writing a review about our company! We greatly appreciate your feedback as it helps us se...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.222\n",
            "  Response: Thank you for your interest in sharing your experience with us! We're thrilled to hear that you would like to write abou...\n",
            "\n",
            "üìö Retrieval (Œî 0.057)\n",
            "\n",
            "======================================================================\n",
            "Query 3/10 - Intent: review\n",
            "Novel Query: The shipping was fast but the product didn't meet my expectations - how do I let you know?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'help me to check the eta of the purchase {{Order Number}}...'\n",
            "  Matched intent: track_order ‚úó WRONG!\n",
            "  Distance: 1.101 (VERY FAR!)\n",
            "  ROUGE-L: 0.180\n",
            "  Response: Thank you for reaching out! I'm here to assist you with checking the estimated time of arrival (ETA) for your purchase w...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.305\n",
            "  Response: We're truly sorry to hear that the product you received did not meet your expectations, and we appreciate you bringing t...\n",
            "\n",
            "üî• LLM (Œî 0.125)\n",
            "\n",
            "======================================================================\n",
            "Query 4/10 - Intent: review\n",
            "Novel Query: I want to give you guys a 5-star rating, what's the best way to do that?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'how do i submit some goddamn feedback for a product...'\n",
            "  Matched intent: review ‚úì\n",
            "  Distance: 1.268 (VERY FAR!)\n",
            "  ROUGE-L: 0.272\n",
            "  Response: We appreciate your eagerness to share your feedback about our product. To submit your valuable insights, you can follow ...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.284\n",
            "  Response: I'm thrilled to hear that you would like to give us a 5-star rating! We appreciate your trust and support in our company...\n",
            "\n",
            "üî• LLM (Œî 0.011)\n",
            "\n",
            "======================================================================\n",
            "Query 5/10 - Intent: review\n",
            "Novel Query: Can I post feedback about both the product and customer service in one place?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I don't know how I can send some feedback about a product...'\n",
            "  Matched intent: review ‚úì\n",
            "  Distance: 0.600 (far)\n",
            "  ROUGE-L: 0.270\n",
            "  Response: Grateful you reached out to us with your feedback concern. We understand your desire to provide feedback about our produ...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.226\n",
            "  Response: I understand your suggestion to provide feedback about both the product and customer service in one place. Your input is...\n",
            "\n",
            "üìö Retrieval (Œî 0.045)\n",
            "\n",
            "======================================================================\n",
            "Query 6/10 - Intent: edit_account\n",
            "Novel Query: My phone number changed and I need to update it in my profile settings\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'i have to update the data included on my user i need help...'\n",
            "  Matched intent: edit_account ‚úì\n",
            "  Distance: 1.020 (VERY FAR!)\n",
            "  ROUGE-L: 0.250\n",
            "  Response: Oh, how marvelous it is to embark on this journey of refining and updating the data included in your user profile!I am h...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.351\n",
            "  Response: Thank you for informing us about the change in your phone number. We understand the importance of having the most up-to-...\n",
            "\n",
            "üî• LLM (Œî 0.101)\n",
            "\n",
            "======================================================================\n",
            "Query 7/10 - Intent: edit_account\n",
            "Novel Query: I got married and want to change my last name on file\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'I need to edit my personal information, will you help me?...'\n",
            "  Matched intent: edit_account ‚úì\n",
            "  Distance: 1.196 (VERY FAR!)\n",
            "  ROUGE-L: 0.228\n",
            "  Response: How wonderful it is to see your commitment to maintaining accurate and up-to-date personal information! Rest assured, we...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.267\n",
            "  Response: Congratulations on your marriage! We are thrilled to hear that you want to update your last name on your file. I underst...\n",
            "\n",
            "üî• LLM (Œî 0.039)\n",
            "\n",
            "======================================================================\n",
            "Query 8/10 - Intent: edit_account\n",
            "Novel Query: How do I modify the email address associated with my login?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'need help to modify my user information...'\n",
            "  Matched intent: edit_account ‚úì\n",
            "  Distance: 0.935 (far)\n",
            "  ROUGE-L: 0.181\n",
            "  Response: How admirable it is to witness your proactive approach to modifying your user information! Your dedication to personaliz...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.393\n",
            "  Response: I am here to assist you with modifying the email address associated with your login. I understand the importance of havi...\n",
            "\n",
            "üî• LLM (Œî 0.213)\n",
            "\n",
            "======================================================================\n",
            "Query 9/10 - Intent: edit_account\n",
            "Novel Query: Need to switch from personal to business account details - can I do that?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'i dont know how to switch to the standard account...'\n",
            "  Matched intent: switch_account ‚úó WRONG!\n",
            "  Distance: 0.799 (far)\n",
            "  ROUGE-L: 0.204\n",
            "  Response: No worries! I'm here to help you with switching to the standard account with ease:\n",
            "\n",
            "1. Login to Your Account: Begin by l...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.202\n",
            "  Response: I'm really glad you're thinking about switching from a personal account to a business account to take advantage of the a...\n",
            "\n",
            "üìö Retrieval (Œî 0.001)\n",
            "\n",
            "======================================================================\n",
            "Query 10/10 - Intent: edit_account\n",
            "Novel Query: The billing address I have on file is old, I need it corrected\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Retrieval:\n",
            "  Matched to: 'i have ot change to the standard account how do i do it...'\n",
            "  Matched intent: switch_account ‚úó WRONG!\n",
            "  Distance: 1.048 (VERY FAR!)\n",
            "  ROUGE-L: 0.168\n",
            "  Response: Certainly! I'm more than happy to assist you in transitioning to our {{Account Type}} account. Let's ensure a smooth and...\n",
            "\n",
            "LLM:\n",
            "  ROUGE-L: 0.203\n",
            "  Response: We appreciate your concern about the billing address on file. We understand the importance of having accurate and up-to-...\n",
            "\n",
            "üî• LLM (Œî 0.035)\n",
            "\n",
            "======================================================================\n",
            "STRESS TEST RESULTS: Novel Queries on Sparse Intents\n",
            "======================================================================\n",
            "\n",
            "Retrieval (26-29 examples/intent): 0.2271 ROUGE-L\n",
            "LLM (trained on same data):        0.2875 ROUGE-L\n",
            "\n",
            "Average retrieval distance: 0.952\n",
            "  (Higher = worse matches, <0.5 is good, >1.0 is bad)\n",
            "\n",
            "Difference: +0.0605\n",
            "\n",
            "Head-to-head: LLM 7/10, Retrieval 3/10\n",
            "\n",
            "======================================================================\n",
            "KEY INSIGHT\n",
            "======================================================================\n",
            "‚úÖ LLM DOMINATES on novel queries with sparse training data!\n",
            "   ‚Üí With only 26-29 examples, retrieval can't find good matches\n",
            "   ‚Üí LLM learned patterns and can generalize\n",
            "   ‚Üí THIS IS THE VALUE OF THE HYBRID APPROACH!\n",
            "\n",
            "This demonstrates:\n",
            "  ‚Ä¢ Retrieval needs comprehensive coverage (like full Bitext)\n",
            "  ‚Ä¢ LLM excels with sparse data (like real-world scenarios)\n",
            "  ‚Ä¢ Hybrid approach = best of both worlds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"QLORA TRAINING: MISTRAL-7B ON 450 EXAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Clear memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Load the EXACT same 450 examples\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "df_train_pilot, df_val_pilot = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining on {len(df_train_pilot)} examples (same as Phi-2)\")\n",
        "print(f\"Validation: {len(df_val_pilot)} examples\")\n",
        "\n",
        "# Format prompts - Mistral format\n",
        "def format_prompt_mistral(row):\n",
        "    # Mistral-Instruct uses specific format\n",
        "    return f\"\"\"<s>[INST] You are a helpful customer service assistant.\n",
        "\n",
        "Customer: {row['instruction']}\n",
        "[/INST]\n",
        "{row['response']}</s>\"\"\"\n",
        "\n",
        "print(\"\\nFormatting prompts for Mistral-Instruct...\")\n",
        "train_texts = df_train_pilot.apply(format_prompt_mistral, axis=1).tolist()\n",
        "val_texts = df_val_pilot.apply(format_prompt_mistral, axis=1).tolist()\n",
        "\n",
        "# QLoRA configuration (optimized for Mistral)\n",
        "print(\"\\nConfiguring QLoRA (4-bit + LoRA)...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",  # NormalFloat4 quantization\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,  # Nested quantization for memory efficiency\n",
        ")\n",
        "\n",
        "# Load Mistral-7B\n",
        "print(\"\\nLoading Mistral-7B-Instruct-v0.2 in 4-bit...\")\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"‚úì Model loaded (GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB)\")\n",
        "\n",
        "# Prepare for QLoRA training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# LoRA config for Mistral (targets all linear layers for best results)\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Slightly higher rank for 7B model\n",
        "    lora_alpha=32,  # alpha = 2 * r is common\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],  # All Mistral attention & FFN layers\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "trainable, total = model.get_nb_trainable_parameters()\n",
        "print(f\"\\nQLoRA Parameters:\")\n",
        "print(f\"  Trainable: {trainable:,} parameters\")\n",
        "print(f\"  Total: {total:,} parameters\")\n",
        "print(f\"  Trainable %: {100 * trainable / total:.2f}%\")\n",
        "\n",
        "# Tokenize\n",
        "print(\"\\nTokenizing datasets...\")\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_function(train_texts)\n",
        "val_encodings = tokenize_function(val_texts)\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask']\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask']\n",
        "})\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Training args (optimized for QLoRA)\n",
        "output_dir = '/content/drive/MyDrive/NLP_Project/checkpoints/mistral7b_qlora_pilot'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,  # Can use 2 with Mistral\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 8\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    warmup_steps=50,\n",
        "    optim=\"paged_adamw_8bit\",  # Memory-efficient optimizer for QLoRA\n",
        "    gradient_checkpointing=True,  # Further memory savings\n",
        ")\n",
        "\n",
        "print(\"\\nTraining configuration:\")\n",
        "print(f\"  Model: Mistral-7B-Instruct-v0.2\")\n",
        "print(f\"  Method: QLoRA (4-bit quantization + LoRA)\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "print(f\"  Optimizer: {training_args.optim}\")\n",
        "\n",
        "# Train\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING QLORA TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(\"Estimated time: ~25-35 minutes on A100\")\n",
        "print(\"(Mistral is faster than Gemma!)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "elapsed = (time.time() - start) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"‚úì QLoRA Training complete in {elapsed:.1f} minutes\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save\n",
        "print(\"\\nSaving QLoRA model...\")\n",
        "model.save_pretrained(f\"{output_dir}/final_model\")\n",
        "tokenizer.save_pretrained(f\"{output_dir}/final_model\")\n",
        "print(f\"‚úì Model saved to {output_dir}/final_model\")\n",
        "\n",
        "# Clean up\n",
        "del model\n",
        "del trainer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nüéâ MISTRAL-7B QLORA TRAINING COMPLETE!\")\n",
        "print(f\"Training time: {elapsed:.1f} minutes\")\n",
        "print(f\"Model size on disk: ~100-200MB (just LoRA adapters!)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e2d09e56399f4b23a2140522b4669e15",
            "e053c4815e8c4bea90703828f3fd2358",
            "053d3177ab4f45d2a23bd75c463f0133",
            "8595b1082a514052b97141fd5409e5de",
            "93358bd4e3c04a0f8d0bb7d21e9ae870",
            "ad920f26556f44438df7d288472db706",
            "e01d7248fdb64572996496ed2bc4dcf2",
            "6fff75807bf849adbd1b1c4fa994f019",
            "2296c0c51f914a1fa66ef539c61a2890",
            "b5ff44ed0741422abc3036abcaf4f520",
            "21b3966b93764968a602bbceab0a8f97",
            "25d5bc543b2c47708e5d14ccc8d64425",
            "508ca6f7680640d89541553669e0bddf",
            "b95ed9cd599a48b7bc12551a34b419dc",
            "0ec260d83b7447b1a41a8e6070ac9913",
            "13fb95e048cc4125af8194e41c25593b",
            "f14ec108288d40e4ab40c43373696ad9",
            "4007fb41edbd4e8aa69dbf07b2182f8d",
            "a20bcd6515c241d68c9f77b4b42b2568",
            "b1faf8bf1b7147b98b5e0899d8bdfac0",
            "34ebf00a7b5b4dda9497a8ce9c6e5812",
            "4909be48aaf94e6186b568cdff33362a",
            "97f5b9452bf64569b37a295f3646ba9f",
            "e50203b8e94447348a88989e71c4f546",
            "dd2493dc5e9e4060a3ad5c3288091a37",
            "623d06098e7b48f09e6b7ac2e9ea6381",
            "391ffb1368984fcea7893a6e630d2f51",
            "2484caaee05644d494b5690f1812fe06",
            "1701f3a3e9794664bcebe604efe26c8f",
            "8270f81ff76c40c6bd1c6545baa267c7",
            "75513c7ddaa14ce59f2b562916c8cb77",
            "0dbefde2f7fa4ff6973b6196e852ef18",
            "b799a960c5f543bd87d6dd510ee214f2",
            "0509015f3ff44881bbf07b18bc2c75c4",
            "ef5f4cc9f5d14df79f0ff6a6d4d86727",
            "cc3e7869bf3644dc97fd233b1e30bbb6",
            "e69b3300706d403eab7684ab558ff4c5",
            "1fd59974499d4d8daa3cc88509c8e66b",
            "1838f541f476439d8c9377f664a9ba0a",
            "d0c34eddf21742a0836142733d35559a",
            "b658f5a9520d475bbb4d45296262e3b0",
            "f9d0b5bf78d44932a300d21a06215c2e",
            "d3e4ede27d074782ad79706fdef14cd1",
            "492c68309acb41f1aff0dcfc360c83fa",
            "73d1832504b641e1b25f3fe889c95ccc",
            "1d5283e3ed7842bc84e0898d367d8b71",
            "a6defd21f357479eadf63bae028ff30d",
            "29f35b9392834263a4acd25da19e3ce2",
            "ec86f47d98ab47558562371553630217",
            "fac7772d91854b0a8a5af87e62e45cfb",
            "394e341ce5f145d1b55f7de05a67c3cc",
            "2a1ed359e05a475fbdfa1418061d433c",
            "ddc910a8e05643008efa0365eb286db8",
            "5cc470da69ce494a8f4044e9705fa2dc",
            "6cd01c11d76543259c7842c2f09f14a1",
            "913b0626661b4ce5b8def611b75cafde",
            "0050ca2ccdfe4366bb2932f3e4adad8a",
            "69f7ec1f31f241d7a814d707da4b25a1",
            "3508e92e35b54782b994eff145d4b81c",
            "5c323d3b19994b4c97303fe21d9bff4a",
            "9b898db27c4e4ebaa89bb862bb2dafd4",
            "c5bd7196289445faa7817faf2b69c39e",
            "cd980c57d4904016a6c7fa59ff1ffed0",
            "386edcc69edb49959b76ff7ad03fe74b",
            "1b79add67f73433fba9f9fe1f4d96e60",
            "1632e95dbaf34def8c014e0f048450d3",
            "9ad27377d9744f959a2cb4438ed199a0",
            "7f5bba47db494870be8ad5b2ac71fdc1",
            "7cf74f1b6f0f4e43a661fe3b41a43b2d",
            "b72984a46a804a8589f3e501e92eedda",
            "244d145ea7d54019885fd5d317d0c8c8",
            "3274985fe7084eefbeb60e6b95d07667",
            "c99b79f1dc95491080383fe718756a3c",
            "662bff737181417b9c91488234ebfdac",
            "7db7423960db49238cd590c173cc9fa0",
            "ef54e59eee35400a8b9f390fc291af11",
            "7a6131260c8e42a7b5adf9d8b535281d",
            "be02fbce6a5844d59e2781de4ecd222b",
            "eb329ea3ccee47e2a64b9ad4563171a5",
            "376fc424ebcd420aa72a22b0d390af11",
            "242705c078bb4ccd9773052cc9fd29eb",
            "81155003e5c846aa9ade9c07fdb3c785",
            "7d73d8135b834e9ca45d33d321414e2d",
            "9387c85fe691413d88657098f6bc54a4",
            "cd756d9571944c6c8139868d39cff16a",
            "dcdaf09807ce488cad174b609ab59439",
            "454302370b3745a5a3a7daff8f1a56bf",
            "1d08f9813ffa422593552c5a53d0620a",
            "30b728a6cb3f4694b5314d10a49dd8ca",
            "bc14c9f53bda47328b263b1ca8ca2f3b",
            "9174647f2184417e88eddb2bb1104c93",
            "4ace56e192814786a325340992761a83",
            "4b7aa223d23b4bc1860de31051fd05be",
            "e3586ebbc2284363b2bea563d549ce57",
            "43c59a40bad34577a799eb978d794401",
            "7e7ac424e7b94af0844740c44e1d0377",
            "96791f6b2a0b4a4d9652f28a72ec55fe",
            "9ad41f3fb9514b6d9fc842ab935824ba",
            "2400cf9e1e8c4984bd35da248fbc0795",
            "5108d23983dd49a5a4b3b98bf321748a",
            "22531b3c76864e6e837b1d8be96ab40d",
            "17ba96b7262748a4ba285e6f818a616d",
            "4611bf0332324f5496ee10fd5705a262",
            "f2b3770cb2814ee0a889a9df45799dc6",
            "0e22d3f90f6f400ea7ed20b24cfb0ffc",
            "fa0baacd8afe43b5812699619ea9aa89",
            "936990fc7957494cba04578e1c767806",
            "e3eae7f658ab47b597301a5f0da6db23",
            "ac3e38629977452b903681473114486f",
            "89e07d33d1954185a1aa3b6b40ed47c0",
            "ac6ab0bd59e74d55b7ec38861b9df6e2",
            "c07b6f1917d448df873bf15f1f3d570b",
            "e05976a7d93446d7a3c35c860fdf3191",
            "83cac2cdae4b4e0da9ff6be14ea4cc1f",
            "86faba14b8714672921cfa7dd319b7a9",
            "fd6b5b2643794760b88ff567ac9f58c5",
            "1513046abe7c4480b5910fb70d86f846",
            "8da1c2f6732e4cdd87e6574f96781a8a",
            "5ddf453f465d4c3da32d4e49854d9d7a",
            "1ddbaa82ff6f45059e808a4d8875d675",
            "153115e2d9de4ff69ebb58eede256d8a",
            "f4366d1203a744deb5e4b25097f221ec",
            "40dc514432234387bf9d09f0608c8576",
            "e5e17e0886c74d699474e13e05ee7228",
            "490eae44a01f4e32a93ba9aad897b1bd",
            "bc98c17dc20741fe97c19ee4cf4b8ac7",
            "d0e9a45fa0404f9a8c3217851ea2c5c5",
            "ba02ce23f85a45ef995b453fc2374120",
            "b09691237a724d5fb65856d32e0feee1",
            "1a041b987ce54c9fafdccdf2f8b15db3",
            "becc8bd839fe44af9ecb2d209fad9c98",
            "9e889b27a0e948528826024720588905"
          ]
        },
        "id": "sXPqWeRBMsy2",
        "outputId": "f402b90e-3071-42d2-f4ab-f2a177a876df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "QLORA TRAINING: MISTRAL-7B ON 450 EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "Training on 450 examples (same as Phi-2)\n",
            "Validation: 50 examples\n",
            "\n",
            "Formatting prompts for Mistral-Instruct...\n",
            "\n",
            "Configuring QLoRA (4-bit + LoRA)...\n",
            "\n",
            "Loading Mistral-7B-Instruct-v0.2 in 4-bit...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d09e56399f4b23a2140522b4669e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d5bc543b2c47708e5d14ccc8d64425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f5b9452bf64569b37a295f3646ba9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0509015f3ff44881bbf07b18bc2c75c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73d1832504b641e1b25f3fe889c95ccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "913b0626661b4ce5b8def611b75cafde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ad27377d9744f959a2cb4438ed199a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be02fbce6a5844d59e2781de4ecd222b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30b728a6cb3f4694b5314d10a49dd8ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5108d23983dd49a5a4b3b98bf321748a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac6ab0bd59e74d55b7ec38861b9df6e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4366d1203a744deb5e4b25097f221ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Model loaded (GPU memory: 15.43 GB)\n",
            "\n",
            "QLoRA Parameters:\n",
            "  Trainable: 41,943,040 parameters\n",
            "  Total: 7,283,675,136 parameters\n",
            "  Trainable %: 0.58%\n",
            "\n",
            "Tokenizing datasets...\n",
            "\n",
            "Training configuration:\n",
            "  Model: Mistral-7B-Instruct-v0.2\n",
            "  Method: QLoRA (4-bit quantization + LoRA)\n",
            "  Epochs: 3\n",
            "  Effective batch size: 8\n",
            "  Optimizer: OptimizerNames.PAGED_ADAMW_8BIT\n",
            "\n",
            "======================================================================\n",
            "STARTING QLORA TRAINING\n",
            "======================================================================\n",
            "Estimated time: ~25-35 minutes on A100\n",
            "(Mistral is faster than Gemma!)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [171/171 07:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.733000</td>\n",
              "      <td>0.709113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.541800</td>\n",
              "      <td>0.669662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.349900</td>\n",
              "      <td>0.675421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "‚úì QLoRA Training complete in 7.3 minutes\n",
            "======================================================================\n",
            "\n",
            "Saving QLoRA model...\n",
            "‚úì Model saved to /content/drive/MyDrive/NLP_Project/checkpoints/mistral7b_qlora_pilot/final_model\n",
            "\n",
            "üéâ MISTRAL-7B QLORA TRAINING COMPLETE!\n",
            "Training time: 7.3 minutes\n",
            "Model size on disk: ~100-200MB (just LoRA adapters!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge_score import rouge_scorer\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARISON: Phi-2 vs Mistral-7B on Sparse Intent Novel Queries\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Same 10 novel queries from before\n",
        "novel_queries = [\n",
        "    # review intent - novel wordings\n",
        "    {\n",
        "        'query': \"I'd like to share my thoughts about the product quality and service I received\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Thank you for your willingness to share your thoughts about the product quality and service you received. We greatly value your feedback as it helps us improve our offerings and customer experience. To submit your review, you can visit our website and navigate to the product page, where you'll find a review section. Alternatively, you can reply to your order confirmation email with your feedback. We appreciate you taking the time to share your experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Where can I write about my experience with your company?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"We're thrilled that you want to share your experience with our company! Customer feedback is incredibly valuable to us. You can write about your experience in several ways: 1) On our website's review section, 2) Reply to your order confirmation email, 3) Through our social media pages, or 4) On third-party review platforms. Which method would be most convenient for you? We look forward to hearing about your experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"The shipping was fast but the product didn't meet my expectations - how do I let you know?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Thank you for sharing this feedback with us, and I apologize that the product didn't meet your expectations despite our fast shipping. Your honest feedback is important to us. To formally submit your review, you can visit the product page on our website and leave a detailed review there. This helps both us and other customers. Additionally, I'd like to understand more about what didn't meet your expectations - could you provide more details so we can address this?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"I want to give you guys a 5-star rating, what's the best way to do that?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"We're absolutely delighted to hear you want to give us a 5-star rating! Your positive feedback means the world to us. The best ways to leave your rating are: 1) On our website's product or service page, 2) Through the review link in your order confirmation email, 3) On Google Reviews or other review platforms you prefer. Your 5-star rating will help other customers discover our services. Thank you so much for taking the time to share your positive experience!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Can I post feedback about both the product and customer service in one place?\",\n",
        "        'intent': 'review',\n",
        "        'reference': \"Absolutely! We encourage comprehensive feedback that covers both product and customer service experience. You can post combined feedback on our website's review section, where you can rate and comment on multiple aspects of your experience. This holistic feedback is incredibly valuable as it gives us a complete picture of your customer journey. Feel free to be as detailed as you'd like - we read every review carefully!\"\n",
        "    },\n",
        "\n",
        "    # edit_account intent - novel wordings\n",
        "    {\n",
        "        'query': \"My phone number changed and I need to update it in my profile settings\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I understand you need to update your phone number in your profile settings. I'm here to help you with that. To update your phone number, please follow these steps: 1) Log in to your account, 2) Navigate to 'Profile' or 'Account Settings', 3) Find the 'Contact Information' section, 4) Click 'Edit' next to your phone number, 5) Enter your new phone number and save changes. You may receive a verification code to confirm the new number. Is there anything else you'd like to update while you're at it?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"I got married and want to change my last name on file\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"Congratulations on your marriage! I'd be happy to assist you with updating your last name on your account. To change your last name, please log in to your account and go to 'Profile Settings' or 'Personal Information'. You'll find an option to edit your name. After updating, you may need to verify this change for security purposes. If you have any documents like an invoice or payment method that also need updating with your new name, please let me know and I can guide you through that process as well!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"How do I modify the email address associated with my login?\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I can help you modify the email address associated with your login. To update your email, please follow these steps: 1) Log in to your account with your current credentials, 2) Go to 'Account Settings' or 'Profile', 3) Look for 'Email Address' or 'Login Information', 4) Click 'Edit' or 'Change Email', 5) Enter your new email address, 6) You'll receive verification emails to both old and new addresses to confirm the change. This security measure ensures your account remains protected. Let me know if you need any assistance!\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"Need to switch from personal to business account details - can I do that?\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I understand you'd like to update your account from personal to business account details. While you can certainly edit your account information, switching to a business account may require additional steps depending on our account types. You can start by updating your profile information in 'Account Settings' to include business details like company name, tax ID, and business address. However, if you want to access business-specific features, you might need to upgrade to a business account type. Would you like me to guide you through either process?\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"The billing address I have on file is old, I need it corrected\",\n",
        "        'intent': 'edit_account',\n",
        "        'reference': \"I can certainly help you correct your billing address. Having accurate billing information is important for smooth transactions. To update your billing address, please: 1) Log in to your account, 2) Navigate to 'Payment Methods' or 'Billing Information', 3) Find your current billing address, 4) Click 'Edit' or 'Update', 5) Enter your new billing address and save changes. Note that this may affect future orders but won't change the address on orders already placed. Would you also like to update your shipping address if it's different?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Load retrieval system (450 examples)\n",
        "print(\"\\nLoading retrieval system...\")\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/bitext_binary_classification.csv')\n",
        "df_indet = df[df['label'] == 1].reset_index(drop=True)\n",
        "df_pilot = df_indet.sample(n=500, random_state=42)\n",
        "df_train_pilot, _ = train_test_split(df_pilot, test_size=0.1, random_state=42)\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "train_embeddings = embedding_model.encode(df_train_pilot['instruction'].tolist(), show_progress_bar=False, convert_to_numpy=True)\n",
        "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "index.add(train_embeddings.astype('float32'))\n",
        "print(\"‚úì Retrieval system ready\")\n",
        "\n",
        "# Load Phi-2\n",
        "print(\"\\nLoading Phi-2 (baseline)...\")\n",
        "phi2_base = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "phi2_model = PeftModel.from_pretrained(\n",
        "    phi2_base,\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "phi2_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n",
        ")\n",
        "print(\"‚úì Phi-2 loaded\")\n",
        "\n",
        "# Load Mistral-7B with QLoRA\n",
        "print(\"\\nLoading Mistral-7B-Instruct with QLoRA...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "mistral_base = AutoModelForCausalLM.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "mistral_model = PeftModel.from_pretrained(\n",
        "    mistral_base,\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/mistral7b_qlora_pilot/final_model\"\n",
        ")\n",
        "mistral_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/NLP_Project/checkpoints/mistral7b_qlora_pilot/final_model\"\n",
        ")\n",
        "print(\"‚úì Mistral-7B loaded\")\n",
        "\n",
        "# Test\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "retrieval_scores = []\n",
        "phi2_scores = []\n",
        "mistral_scores = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING ON 10 NOVEL QUERIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, item in enumerate(novel_queries, 1):\n",
        "    query = item['query']\n",
        "    reference = item['reference']\n",
        "    intent = item['intent']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Query {i}/10 - Intent: {intent}\")\n",
        "    print(f\"Novel Query: {query[:80]}...\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Retrieval\n",
        "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n",
        "    dist, ind = index.search(query_emb.astype('float32'), 1)\n",
        "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n",
        "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n",
        "    retrieval_scores.append(ret_score)\n",
        "\n",
        "    # Phi-2 (simple format)\n",
        "    phi2_prompt = f\"Customer: {query}\\nAssistant:\"\n",
        "    inputs = phi2_tokenizer(phi2_prompt, return_tensors=\"pt\").to(phi2_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = phi2_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=phi2_tokenizer.eos_token_id\n",
        "        )\n",
        "    phi2_resp = phi2_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
        "    phi2_score = rouge_scorer_obj.score(reference, phi2_resp)['rougeL'].fmeasure\n",
        "    phi2_scores.append(phi2_score)\n",
        "\n",
        "    # Mistral-7B (Instruct format with [INST] tags)\n",
        "    mistral_prompt = f\"<s>[INST] You are a helpful customer service assistant.\\n\\nCustomer: {query}\\n[/INST]\\n\"\n",
        "    inputs = mistral_tokenizer(mistral_prompt, return_tensors=\"pt\").to(mistral_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = mistral_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=mistral_tokenizer.eos_token_id\n",
        "        )\n",
        "    mistral_resp = mistral_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Extract response after [/INST]\n",
        "    if \"[/INST]\" in mistral_resp:\n",
        "        mistral_resp = mistral_resp.split(\"[/INST]\")[-1].strip()\n",
        "    if \"</s>\" in mistral_resp:\n",
        "        mistral_resp = mistral_resp.split(\"</s>\")[0].strip()\n",
        "\n",
        "    mistral_score = rouge_scorer_obj.score(reference, mistral_resp)['rougeL'].fmeasure\n",
        "    mistral_scores.append(mistral_score)\n",
        "\n",
        "    print(f\"Retrieval:    {ret_score:.3f} | Dist: {dist[0][0]:.3f}\")\n",
        "    print(f\"Phi-2:        {phi2_score:.3f}\")\n",
        "    print(f\"Mistral-7B:   {mistral_score:.3f}\")\n",
        "\n",
        "    best = max([('Retrieval', ret_score), ('Phi-2', phi2_score), ('Mistral-7B', mistral_score)], key=lambda x: x[1])\n",
        "    print(f\"üèÜ Winner: {best[0]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nAverage ROUGE-L Scores:\")\n",
        "print(f\"  Retrieval (450 examples):    {np.mean(retrieval_scores):.4f}\")\n",
        "print(f\"  Phi-2 (2.7B, 450 train):     {np.mean(phi2_scores):.4f} (+{(np.mean(phi2_scores)-np.mean(retrieval_scores))/np.mean(retrieval_scores)*100:.1f}%)\")\n",
        "print(f\"  Mistral-7B (7B, 450 train):  {np.mean(mistral_scores):.4f} (+{(np.mean(mistral_scores)-np.mean(retrieval_scores))/np.mean(retrieval_scores)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nHead-to-head wins over Retrieval:\")\n",
        "phi2_wins = sum([1 for p, r in zip(phi2_scores, retrieval_scores) if p > r])\n",
        "mistral_wins = sum([1 for m, r in zip(mistral_scores, retrieval_scores) if m > r])\n",
        "print(f\"  Phi-2:        {phi2_wins}/10\")\n",
        "print(f\"  Mistral-7B:   {mistral_wins}/10\")\n",
        "\n",
        "print(f\"\\nMistral-7B vs Phi-2:\")\n",
        "mistral_vs_phi2 = sum([1 for m, p in zip(mistral_scores, phi2_scores) if m > p])\n",
        "print(f\"  Mistral-7B wins: {mistral_vs_phi2}/10\")\n",
        "\n",
        "improvement = (np.mean(mistral_scores) - np.mean(phi2_scores)) / np.mean(phi2_scores) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONCLUSION\")\n",
        "print(\"=\"*70)\n",
        "if mistral_vs_phi2 >= 8:\n",
        "    print(f\"‚úÖ Mistral-7B DOMINATES Phi-2 ({mistral_vs_phi2}/10 wins)!\")\n",
        "    print(f\"   ‚Üí {improvement:+.1f}% improvement in ROUGE-L\")\n",
        "    print(\"   ‚Üí Model scaling significantly helps sparse intent generalization\")\n",
        "elif mistral_vs_phi2 >= 6:\n",
        "    print(f\"‚úÖ Mistral-7B outperforms Phi-2 ({mistral_vs_phi2}/10 wins)\")\n",
        "    print(f\"   ‚Üí {improvement:+.1f}% improvement in ROUGE-L\")\n",
        "    print(\"   ‚Üí Larger model provides measurable benefit\")\n",
        "else:\n",
        "    print(f\"‚âà Mistral-7B and Phi-2 comparable ({mistral_vs_phi2}/10 wins)\")\n",
        "    print(f\"   ‚Üí {improvement:+.1f}% change in ROUGE-L\")\n",
        "    print(\"   ‚Üí Model size less critical than training data quality\")\n",
        "\n",
        "print(f\"\\nüéØ KEY FINDING: Both LLMs beat retrieval on sparse intents!\")\n",
        "print(f\"   Retrieval: {np.mean(retrieval_scores):.4f}\")\n",
        "print(f\"   Best LLM:  {max(np.mean(phi2_scores), np.mean(mistral_scores)):.4f}\")\n",
        "print(f\"   Improvement: +{(max(np.mean(phi2_scores), np.mean(mistral_scores)) - np.mean(retrieval_scores))/np.mean(retrieval_scores)*100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5547a40b9a8418c9e670a3c68229f5d",
            "f4e513203f0344eba95e6f3050f708ef",
            "3ef78d89994c40288d40755615675b54",
            "b41ef9fa1b7e463eaf727e0bb2a75624",
            "9e627d7c49134333a9d098471a79603e",
            "846e9ad1cde04089818b0bca11ee6f85",
            "ced60d5398784bbd805bcc854bd68fa6",
            "1079cfd200494bc492f44848d266f18a",
            "daf5ff0b903845ae86c0835b74d16b47",
            "b2f07934a6e04229ba93718f8951d4e1",
            "31b21da5b62140e390e54f9057e86edb",
            "aaf2fdfba16c42afbfa67ee0833c59c7",
            "c4b67d9ad24c4aee837e6c0d6c78c01e",
            "d20e56c9abe6487e8cc734434dff2f47",
            "51939b757e1644bdab11331beb955891",
            "da9fa1d211d3442b83533f92a2b3d7aa",
            "c8eed2235b74441c85660a4dac41a079",
            "0e8aa275a6fa4109a6b5cf92eac915ef",
            "4ed4a191681b48e9adaf902e34e6be8e",
            "f966635717834b0aad59d0467d0b6f92",
            "3e0afdf0639d404494d002057540afad",
            "7b5a2a3435664d7f83ac3dd3e4b8c912",
            "bbd303bb39464af1ae5fad70e981e0f0",
            "3a21d25adb0d4a258939644222a7bb07",
            "59bf8db5fd1e4459b0d5c0f9a5523eb1",
            "e01b60f39aac4b84b6a8c4676f66ea1a",
            "dde43c1fa7d34b41bb6a5af7e133e967",
            "64e2e23d85da41a8960411c244203228",
            "4deecf6f82e94eea878f8c5c32e95e3a",
            "e23f95d567164d588bd894e3dcee297c",
            "ba08690f619e4c55b6ef314d03ff0213",
            "66806eb30a1e4768b8efbbd0cafea768",
            "70d4330db536416d9b68cc281f3afe1c",
            "aa9cd6fb36d54e1ab123304a45fc12ad",
            "c94adb751ec74e5c90a16514bc4a527a",
            "53f6cfe3de7c4a6089b3658183bee208",
            "f9090f3d491d468ab068285d098abc25",
            "fcb13cee354046b1a0246d7509b11cb4",
            "ba47df96945d4615b82282a945e77496",
            "6b3ca1fbc6f04a5aa028f633ff4ea151",
            "89e4046839194382b67ef7bca968b933",
            "89b420dd039d4db191ea197da73ad1a8",
            "74c6bb6884de4e1d902b325d3c2f1d60",
            "dc9f1334b49e4079ac77ffffccd6ced4",
            "d62282abaf60440796ced7cfceb05228",
            "90a970b2b87d4729a4791bad25a3f563",
            "d45510e15546453495bae1393b7ea900",
            "af769d263d624e06b593acbcd689fc7d",
            "b29b3ed2ffe647ccb46cacd443f7d142",
            "78df89ea7b334e1aa33ae2caa513a872",
            "971dda74eaa74b59981294eb16452fd2",
            "a105a18d95d34800bb058f8dafca1205",
            "7df1d3114514432984bfe98ea86fcc2f",
            "4a59863e6be64d1eb0057d15adbf54fb",
            "2ed55af162d94315b706ac5f65fc7568",
            "09b16c9abaaa442683783b716362dcf1",
            "302b46de13b74a088a7d7a412f4a7135",
            "f294da832c4746c6b8c4ead2c3d3fe26",
            "04cca402bbe149b6a60df702add49a60",
            "c4af28d2c1714dafb40b650719c52c17",
            "3b73d24a21da47c6af8e410b651d6acd",
            "c2d62b95c9fc4c388643a4c823697757",
            "7b5caf9662c6409fa325f851bc947549",
            "a45602c760f84d06b041e27ae08359f4",
            "fb06ed2fa2964ea0a7a4492634a0320d",
            "e214e038adbd463ab14194c0f4f8f9c5",
            "b026eff4fc8748799aeb293ea3379db6",
            "6f50c3e583e84286b0c1f5084266f4a9",
            "f26b334ebc93453baa3790fdb9e03363",
            "4b110c7a74ee434392674083026718b0",
            "e837090e1a924f9cb61a7b1da57c328e",
            "e35240ab85954dd882391e8cd24d64c9",
            "70ae6f07a14b447cbd21af86f495173f",
            "bcecf62e52a34411915d77a39bc74896",
            "459efdebf20d47ce883e90d8bf8a47a1",
            "2a323bb9f892442fbadb57c006d369c6",
            "0be4f6073fbf4942bb5e6853f201cec6",
            "25511ad89fc14db6a242874066bbdd4f",
            "3554defe90bf4070bcb46c2bfda9c853",
            "fde1287ffd364b68bec8c30cef203087",
            "1bb52dcd536a4ba6a290d2a0b5562e74",
            "0eb8f73c6bb747eaba19a189a45e708a",
            "31f4d60599324adcb48e0541ab443169",
            "a81a109e07b4438bbcdaf327b3f4cedb",
            "6b08a3f0900442539b3c9f482a4ec3ba",
            "489de3f4c4504df8946e6aabff722642",
            "22e156c7eec944b5bffebbe800ee7f37",
            "0c3a9c8bc68549f2bb5e273fbec9303a",
            "1ed82d9dcf134aa4a1fd9f470dd9ce62",
            "1dfda0179542416383670feea3a4f4b9",
            "cadcdafb87e941b3afaa7285c8e88257",
            "9c5b501f0f3b478dbedd10130cc1763a",
            "9f17e0b9138147778fc37cd1dee5bd46",
            "dbbe1545f3554468899d45b305287698",
            "8e09adafd7d149c691cd0267fdcd9fb2",
            "68835487f34341fc8335e64242c1baac",
            "8fa6efdf8aef46b193891f5a49c168d7",
            "79e97f5b5f074dcabd6d8ad4192b6765",
            "54514f62de634e399f5c09af058661b4",
            "52195f16ac1341ce9e0b5c71c24e67f6",
            "37e78e59a8454f80a160f1367b2830a7",
            "385e78905c9249f2899043210cbede37",
            "04a96559793f44ae9e87e792c2cdd426",
            "07c4d4c1e4c84f69bb5278129f662593",
            "ac301ad889b949f7bb59b9f3a2571dd0",
            "1a7e697fac3541068578ffd2df9891e0",
            "4ad5eddfdca54f94a23763169c703637",
            "5a5767071a5e456d840404b62f055788",
            "854acf131836476689e7d1c2c4a9e5d3",
            "a0b2d1c223d043068c9961847d4981f6",
            "0771c34131c34b9b850761b0a7edc90a",
            "858522702f434422b5fc0c8f9f3a0088",
            "96f1831b796f4ee7a20d67eed4b8cf7d",
            "195b9fe5baa2485a9877066efe26bcd5",
            "3cd292d46888428c81c9472c489c732f",
            "297b0c975625412294a3fe8f106fdc08",
            "c727d4cef8bf4863bf6520e78e4ef695",
            "8a665e3c79b248a3b3e10843daf0f496",
            "7273ecb390714f8ea6d83aae3faee09e",
            "f8a4f3fbf41644678dd6e2759d24e800",
            "f9590ab9ec4246a1b0a06bc6334bf224",
            "6e2d8ced527744c4a7c71a5bcf0a05aa",
            "7a1090b3a79947e49de4b77324323acf",
            "b10669d1bff04430ab4f956411a4cf27",
            "8eaac898701746b98633943e97d85b11",
            "befd4caf1d1543f5a68d3b005198d291",
            "d6ad49cb242642929e077f31de690ea9",
            "bb71830b90d6403f826cd22784fedb20",
            "e4c65e905d08435bb8e10631dc9bcb79",
            "a7499c4348504a7bbe55f7647ba6d95e",
            "b79febc8b6fb4d68affd206c0d282ce2",
            "36bfda371a75467eab264e5b67e56ff7",
            "7d6a2e5d3b1341dd910b8d6b090530b1",
            "12b7cff9cdcf40758dca72daa3f15fef",
            "3bb2b44197104af39e14911c0b7aa595",
            "7ec92bbd1a87479689693f47a01a3184",
            "3ceddced8d414521884e2af24a55bf5d",
            "d0bd2edcef134f59bf0aae0e6fab6f5b",
            "28ef965b78cc4ce8bcdbc74282e4df69",
            "cfcb92daf54543d0a31c3c57a19144fd",
            "4abed7fcba17455f83766ba51538623b",
            "9f4c55aac24341e782bdaebdd4bf29ec",
            "875ba3c5dffc45f1937fdda9e2dfe673",
            "f24b745b2a2448439267558ba827b240",
            "8c8b9ffe946044d28f60ebe2e215ae19",
            "02cff50b8f0242fb9605b14b0855579e",
            "e213ca719cd34cb1bc45e8dc70f9c627",
            "c773bfb40c004792ad1c532a04549187",
            "f0c3f7af3c794fa39c8490d93b90d07d",
            "83507c32e2574676b7454f1d9f2a25de",
            "f3ba495070ff44a2b3f90cb7b5691f5b",
            "ea9954e851c24dddb777fee0d99136b2",
            "3da27a3e7d934bdc81c5a0495f9d3fc4",
            "f5445942341647969ba433182959edcb",
            "e960b24e37b64aaa88171e85b687ee44",
            "46e98958ceeb49c0831dd04ffffb54f8",
            "9fb849868f4e4b759e4204229463f0f1",
            "2fee0264ee364694b5629aabcc5269e5",
            "5b96a2fb2e8b445b95c72c6ff6feceac",
            "11e6b5269b414f098f10145ead2db7fc",
            "1306bca406874f2c98f1055eb6bc040e",
            "e5f21e55b457427fa50b0965a04575f4",
            "dd40c82f06d84ef6b973172c40955d03",
            "71272d6edfa145f29bd6426ec0b457e8",
            "5529c81626f74750897dcbd3e51fd714",
            "ca047e845e1f480db4afd335069fdc20",
            "111dcc730eac46cab253d06492d62230",
            "2d2e1ab35aed475fa0447fb7ed65799b",
            "e190569c7d5f408c907a16dc5b27503b",
            "47463f5f180f440aa6a1382dba2593b6",
            "bd98fda345d14f048c797bd3fce54118",
            "5bf377b3f217472abf2f63a8032feb25",
            "39df39472c194c2b86f6bbd0e194b003",
            "8684abce60e54fd79e7e2d304dd9e6ec",
            "4b0780ca5a2c44e2aa7b23a1f38a5fa6",
            "46c71d639ca24ee6a0dca4d229e5ddb2",
            "3c7506eb73c541299e70b6cb0b1f0c0a",
            "d47dd03c432e4424847fdb5f7f934630",
            "878df13f89ae483b9cd4a1a584ba55ca",
            "1b813ea8b1434e92a68f4dcb642de647",
            "7dc5b77e3cc74435a3832ffe7f06f819",
            "9087b116938b459dbd064bdd09dd3d2d",
            "987c8e40f61040f6bc113c3873be94b9",
            "6ec8a611f6704aeb97ed82f9343156e0",
            "ff45c30abcb347b59beb2592ca35bffa",
            "d0715ff680f14ab9af0f3564f8622ba6",
            "9815640f8d1e466d95143d6230fdd41e",
            "180738e9bcfa49d8bd46a691daf330bd",
            "f3ec851b07844814b77b7943f9382f55",
            "e8da4c84a420499d95692032dcfc7682",
            "2a6489f6a5a440b49776ce41bd90f759",
            "11916a41ac944efe8f4509f7e492650c",
            "2391e3d671d840c4a218a20fc96b610e",
            "b3700b7980404a43b7d3e325e24db338",
            "9ba3171febe34433af2205de3e2baa53",
            "3bdb547b554647aab028075e0a8f5595",
            "1f86e1e699a7416a8de90463cae30831",
            "055b0212fc4448e685c66115e5f39fa7",
            "187d6c5d644d41f485d0cc07ba9871fc",
            "1d86fce70f5d42eea0a4a873439b6d21",
            "407ddafe3d084e008fa4460298ec8dcd",
            "71d328233fbb4e73afef75fa3f56dae3",
            "4248b389f0394a33b64c75929cb81e04",
            "8de23a724c9249ab918cd1e885983317",
            "19e626d817304e3692a22a82ec007994",
            "dc3086377784447f8689d7a8c6eda949",
            "4b545723ff7e4b08a5947445c9652262",
            "efb566ab3e5641e9946fb9b6cc2b5803",
            "83bbbf6dcbf840928b0fe19d25153fd0",
            "d631f52c569f4b188352e406591b649f",
            "04249f02d91b49709f51d1a5985c0d64",
            "67d7d38d1c1646c6b8de42f904a28fd2",
            "99d118e5859246afba05ceb3c027d0c9",
            "8e1a6c7197534bde8b923622fdfd6b2c",
            "210b1f5084a34a0d94657ebd3771990a",
            "f433af812e4a437092f8b5783ea1d15b",
            "789a05985c1a4458b7fb1ca3ad1ce95c",
            "bc12173ffe0a49b0bb5cf2a7229c5bd6",
            "8319df47b1aa4b43ad9ce080369dc2cc",
            "0c94f86ad3a84719bdb2000dbf4ace1c",
            "d574c0eacca74d129bbf9b94be314fc7",
            "7770c9ac65da4054a365526308f78d62",
            "0912d63dd5d64d02bb6d05f294411563",
            "8c7bf8527be949d1ad097ae03bedb07c",
            "22ecdcb2fc4c47aab87fdaecd23e92bd",
            "90d21800250341559cd97c387b2b9fc7",
            "2c840403105e40fdb8e8e7a5b59c021d",
            "4ff3fa5ac6af404c9da2cf302cfee424",
            "72f0b200cb59483390c9f9a5c0892233",
            "96a93e663f064c339d9fb069e9d18be5",
            "1047a01432154866a7acc0ceb10ac4c0",
            "5a0ed3e1e6434a8385423dd102e9e240",
            "3e6862e84efb438997c2b852b6dc6dc9",
            "a9dbfd880bec4ed6a4d0ea0129716784",
            "c8d24e24559e41caaf572d4c41636f51",
            "a30fd39bdb4840e8b337cbfc594f8e7b",
            "ca52be93e567412db69d06b60516f8fd",
            "b16cd7736c6448189768fa03eaa2fa46",
            "b52f3bc00b194d9ba92f91248e926548",
            "51a67434ff0847c98e977e5d9d8c567f",
            "18e093caaaef407e89b0b32b9383f69f",
            "ca0b9eddbf2643c38ee92ac8a703aa5e",
            "5c705fae09e74de7b1de7faa172eeeda",
            "243e6e116dec4f1c9419675896383716",
            "57bf727a577644fe80d858d2e033e14f",
            "1335768e8d514628abbc496df8cadbac",
            "726f758c564347848a53f4e5e36d954f",
            "4ba6d108644149ec916149efaa507587",
            "1867d10b2be043d98e376fa971402de7",
            "6b5ed10b303d4a0994e11a17bbd2f5f0",
            "29a1de07a61147a8a88e25dda58f6d7b",
            "8e485e2a288b49a796311b644e87faf2",
            "73322b5ab39d4238bd3ec48874802e2f",
            "248c3c35c8d04703aeb3724d829cb221",
            "ce58f98bd89f4282b0c41e4514bfc366",
            "6ab6ba669bea420f9e166725bc943665",
            "c60b35eeee014a8b80cdcc0bcddd5df8",
            "9ac1d166b1c64f59b4a91f6036bde2d6",
            "d58a381041ef46eb8b5387bdce99063a",
            "0472262adc434efcba7db43d418e837d",
            "debff885d94041b18f525e48fd556896",
            "df83be4597cd4f689da5c64c8f49acc0",
            "3b593521e7ff4f818d43f5abc9df6cbc",
            "f5fc00ecefed40b08ea7545d2f39612f",
            "2889214582704e74a4f4a611f2963962",
            "018a710b78b44c68990a82178d170d30",
            "66d71bb528bc4a79a90174fc98b952ba",
            "424e8f8e534d49da94a073078aa6e7cd",
            "ac3b7154ec924e48be020be3ed90fd62",
            "1fdc9ee0f63845648a8881376ec25da8",
            "16b2dc54f48d4ebebb780a6704a785ad",
            "c3b959620df64739b271e8225eb492fa",
            "5c8ebd0f8be148c9b79e0a6cddf0ce82",
            "7b50989bace54fdab0d38c507122f6c2",
            "07d7515654f24001ae09c0cc4588d72a",
            "949ac294f3ce488cac40769ad1d9abd9",
            "aa676d33bcf04bd1be004c3a8e872473",
            "ba2dbbf4c7fe41758768f32f1f50281c",
            "cb60c7671ba94bcdb2277b75e1e38226",
            "72f9b14c95944e50b8c63450578a2ab2",
            "4e842f21614148cba95a993f16b00c90",
            "13d3763f20fc420cb58fc9a0321a63be",
            "26a80aa5985c4d638c28e2ede1eb981c",
            "a5534a7e81164d9da404dfd001964459",
            "082dae49e96f49e1bd83fa7730bac7cb",
            "997baa1cde4e48fba9f61e1fb3fbab47"
          ]
        },
        "id": "4-WezgfPUk2x",
        "outputId": "4af51591-b798-4b62-84b3-2b5acd73987e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMPARISON: Phi-2 vs Mistral-7B on Sparse Intent Novel Queries\n",
            "======================================================================\n",
            "\n",
            "Loading retrieval system...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5547a40b9a8418c9e670a3c68229f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaf2fdfba16c42afbfa67ee0833c59c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbd303bb39464af1ae5fad70e981e0f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa9cd6fb36d54e1ab123304a45fc12ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d62282abaf60440796ced7cfceb05228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09b16c9abaaa442683783b716362dcf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b026eff4fc8748799aeb293ea3379db6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25511ad89fc14db6a242874066bbdd4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ed82d9dcf134aa4a1fd9f470dd9ce62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52195f16ac1341ce9e0b5c71c24e67f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0771c34131c34b9b850761b0a7edc90a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Retrieval system ready\n",
            "\n",
            "Loading Phi-2 (baseline)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e2d8ced527744c4a7c71a5bcf0a05aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6a2e5d3b1341dd910b8d6b090530b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24b745b2a2448439267558ba827b240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e960b24e37b64aaa88171e85b687ee44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca047e845e1f480db4afd335069fdc20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c7506eb73c541299e70b6cb0b1f0c0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "180738e9bcfa49d8bd46a691daf330bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Phi-2 loaded\n",
            "\n",
            "Loading Mistral-7B-Instruct with QLoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "187d6c5d644d41f485d0cc07ba9871fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d631f52c569f4b188352e406591b649f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d574c0eacca74d129bbf9b94be314fc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a0ed3e1e6434a8385423dd102e9e240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c705fae09e74de7b1de7faa172eeeda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "248c3c35c8d04703aeb3724d829cb221"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2889214582704e74a4f4a611f2963962"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "949ac294f3ce488cac40769ad1d9abd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Mistral-7B loaded\n",
            "\n",
            "======================================================================\n",
            "TESTING ON 10 NOVEL QUERIES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Query 1/10 - Intent: review\n",
            "Novel Query: I'd like to share my thoughts about the product quality and service I received...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.238 | Dist: 0.752\n",
            "Phi-2:        0.281\n",
            "Mistral-7B:   0.373\n",
            "üèÜ Winner: Mistral-7B\n",
            "\n",
            "======================================================================\n",
            "Query 2/10 - Intent: review\n",
            "Novel Query: Where can I write about my experience with your company?...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.279 | Dist: 0.801\n",
            "Phi-2:        0.247\n",
            "Mistral-7B:   0.261\n",
            "üèÜ Winner: Retrieval\n",
            "\n",
            "======================================================================\n",
            "Query 3/10 - Intent: review\n",
            "Novel Query: The shipping was fast but the product didn't meet my expectations - how do I let...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.180 | Dist: 1.101\n",
            "Phi-2:        0.138\n",
            "Mistral-7B:   0.249\n",
            "üèÜ Winner: Mistral-7B\n",
            "\n",
            "======================================================================\n",
            "Query 4/10 - Intent: review\n",
            "Novel Query: I want to give you guys a 5-star rating, what's the best way to do that?...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.272 | Dist: 1.268\n",
            "Phi-2:        0.197\n",
            "Mistral-7B:   0.220\n",
            "üèÜ Winner: Retrieval\n",
            "\n",
            "======================================================================\n",
            "Query 5/10 - Intent: review\n",
            "Novel Query: Can I post feedback about both the product and customer service in one place?...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.270 | Dist: 0.600\n",
            "Phi-2:        0.233\n",
            "Mistral-7B:   0.256\n",
            "üèÜ Winner: Retrieval\n",
            "\n",
            "======================================================================\n",
            "Query 6/10 - Intent: edit_account\n",
            "Novel Query: My phone number changed and I need to update it in my profile settings...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.250 | Dist: 1.020\n",
            "Phi-2:        0.352\n",
            "Mistral-7B:   0.276\n",
            "üèÜ Winner: Phi-2\n",
            "\n",
            "======================================================================\n",
            "Query 7/10 - Intent: edit_account\n",
            "Novel Query: I got married and want to change my last name on file...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.228 | Dist: 1.196\n",
            "Phi-2:        0.290\n",
            "Mistral-7B:   0.274\n",
            "üèÜ Winner: Phi-2\n",
            "\n",
            "======================================================================\n",
            "Query 8/10 - Intent: edit_account\n",
            "Novel Query: How do I modify the email address associated with my login?...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.181 | Dist: 0.935\n",
            "Phi-2:        0.361\n",
            "Mistral-7B:   0.369\n",
            "üèÜ Winner: Mistral-7B\n",
            "\n",
            "======================================================================\n",
            "Query 9/10 - Intent: edit_account\n",
            "Novel Query: Need to switch from personal to business account details - can I do that?...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.204 | Dist: 0.799\n",
            "Phi-2:        0.205\n",
            "Mistral-7B:   0.251\n",
            "üèÜ Winner: Mistral-7B\n",
            "\n",
            "======================================================================\n",
            "Query 10/10 - Intent: edit_account\n",
            "Novel Query: The billing address I have on file is old, I need it corrected...\n",
            "----------------------------------------------------------------------\n",
            "Retrieval:    0.168 | Dist: 1.048\n",
            "Phi-2:        0.222\n",
            "Mistral-7B:   0.199\n",
            "üèÜ Winner: Phi-2\n",
            "\n",
            "======================================================================\n",
            "FINAL COMPARISON\n",
            "======================================================================\n",
            "\n",
            "Average ROUGE-L Scores:\n",
            "  Retrieval (450 examples):    0.2271\n",
            "  Phi-2 (2.7B, 450 train):     0.2527 (+11.3%)\n",
            "  Mistral-7B (7B, 450 train):  0.2729 (+20.2%)\n",
            "\n",
            "Head-to-head wins over Retrieval:\n",
            "  Phi-2:        6/10\n",
            "  Mistral-7B:   7/10\n",
            "\n",
            "Mistral-7B vs Phi-2:\n",
            "  Mistral-7B wins: 7/10\n",
            "\n",
            "======================================================================\n",
            "CONCLUSION\n",
            "======================================================================\n",
            "‚úÖ Mistral-7B outperforms Phi-2 (7/10 wins)\n",
            "   ‚Üí +8.0% improvement in ROUGE-L\n",
            "   ‚Üí Larger model provides measurable benefit\n",
            "\n",
            "üéØ KEY FINDING: Both LLMs beat retrieval on sparse intents!\n",
            "   Retrieval: 0.2271\n",
            "   Best LLM:  0.2729\n",
            "   Improvement: +20.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ru81_lxVCNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}